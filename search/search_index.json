{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PHARMBIO","text":"<p>Pharmbio Python Package is crafted to meet the specific needs of our laboratory at Pharmbio. This tool stands at the forefront of simplifying and enhancing the data analysis workflow. Designed with efficacy, precision and user-friendliness in mind, Pharmbio is tailored for researchers, student, and bioinformaticians who work in the lab and want to make data analysis a bit easier.</p>"},{"location":"#who-is-pharmbio-for","title":"Who is Pharmbio for?","text":"<p>Pharmbio is an invaluable resource for everyone that works in the Pharmaceutical Bioinformatics Research Group Pharmbio and need  to perform different routine from quality control to ml.</p>"},{"location":"#what-does-pharmbio-offer","title":"What Does Pharmbio Offer?","text":"<p>Our package is engineered to integrate seamlessly into your workflow, especially within Jupyter notebooks, offering a simplified yet powerful approach to pharmaceutical data analysis. Right now it is in its very first stage but we tried to make it with this key points in mind:</p> <ol> <li>Modular Design: Flexibility is at the core of Pharmbio. Its modular architecture allows for easy customization and integration of new features, catering to the evolving needs of pharmaceutical bioinformatics research.</li> <li>Enhanced Efficiency: Pharmbio is designed to minimize the need for extensive scripting. It encompasses all the necessary options for a comprehensive data analysis process, from data retrieval and quality control to advanced analytics, all within a streamlined framework.</li> <li>Pipeline Standardization: Consistency is key in scientific research. Pharmbio aids in establishing a standard protocol in the lab for data processing and routine analysis, ensuring reliability and reproducibility of results.</li> </ol>"},{"location":"#the-documentation-your-guide-to-mastery","title":"The Documentation: Your Guide to Mastery","text":"<p>The Pharmbio documentation is your comprehensive guide to unlocking the full potential of this package. It includes: - Detailed Tutorials: Step-by-step guides to get you started and help you master Pharmbio. - Function and Class Descriptions: Exhaustive details of every feature, function, and module within the package through API reference.</p>"},{"location":"blog/","title":"Pharmbio Blog","text":"<p>Welcome to the inaugural post of the Pharmbio Blog, a dedicated space for sharing insights, updates, and detailed discussions about the multifaceted world of pharmaceutical bioinformatics. This blog is an extension of the Pharmbio Package documentation, designed to enrich your understanding and engagement with the tools, techniques, and trends shaping the future of drug discovery and development.</p>"},{"location":"blog/#our-vision","title":"Our Vision","text":"<p>At Pharmbio, we believe in the power of knowledge sharing and community engagement. This blog is a testament to that belief, offering a platform where experts, enthusiasts, and professionals alike can explore the depths of pharmaceutical bioinformatics. Here, we aim to not just inform, but also inspire and provoke thought, fostering a community of learning and innovation.</p>"},{"location":"blog/#what-to-expect","title":"What to Expect","text":"<p>The Pharmbio Blog will serve as a hub for a variety of content related to our work and the broader field of pharmaceutical bioinformatics, including but not limited to:</p> <ul> <li>In-Depth Articles: Detailed explorations of specific aspects of Pharmbio, from algorithmic advancements to practical applications in drug discovery.</li> <li>Research Insights: Summaries and discussions of cutting-edge research in the field, highlighting how these developments can be integrated into the Pharmbio ecosystem.</li> <li>Tutorials and Guides: Step-by-step instructions and best practices for utilizing Pharmbio tools in various research scenarios.</li> <li>Industry Trends: Analysis of emerging trends in pharmaceutical bioinformatics and their potential impact on the Pharmbio project and its users.</li> </ul>"},{"location":"blog/#join-the-conversation","title":"Join the Conversation","text":"<p>We invite you to engage with our content, share your thoughts, and contribute to the discussions. Your insights and feedback are invaluable in shaping the future of Pharmbio and fostering a vibrant community.</p>"},{"location":"blog/2023/10/12/data-outlier-detection-techniques/","title":"Outlier Detection Techniques: Use Cases, and Distinctions","text":"","tags":["Z-Score","Interquartile Range"]},{"location":"blog/2023/10/12/data-outlier-detection-techniques/#introduction","title":"Introduction:","text":"<p>Outlier detection is a critical task in data preprocessing, especially in fields like fraud detection, network security, and quality control in manufacturing. The identification and handling of outliers, which are data points that significantly deviate from the other observations, is crucial as they can skew the analysis and lead to incorrect conclusions. This essay delineates various outlier detection methods, elucidates their practical applications, and underscores the differences among them.</p>","tags":["Z-Score","Interquartile Range"]},{"location":"blog/2023/10/12/data-outlier-detection-techniques/#outlier-detection-methods","title":"Outlier Detection Methods:","text":"<p>Statistical Methods:</p>","tags":["Z-Score","Interquartile Range"]},{"location":"blog/2023/10/12/data-outlier-detection-techniques/#standard-deviation-sd-method","title":"Standard Deviation (SD) Method","text":"<p>When <code>method</code> is set to \"SD\", the function uses standard deviation as the basis for outlier detection:</p> <ul> <li>First, data is normalized using a specified normalization method (<code>zscore</code> or <code>minmax</code>).</li> <li>For each QC metric (module), the data values that fall below or above a certain threshold, set by <code>sd_step_dict</code> or <code>default_sd_step</code>, are flagged as outliers. These thresholds are usually set in terms of standard deviations. For instance, a typical choice could be values that are more than 2 standard deviations away from the mean.</li> </ul> <p>Mathematically:</p> \\[\\text{Outliers} = \\{ x \\mid x &lt; \\mu - k\\sigma \\} \\cup \\{ x \\mid x &gt; \\mu + k\\sigma \\}\\] <p>Where:</p> <ul> <li>\\(x\\) is a data point</li> <li>\\(\\mu\\) is the mean of the data</li> <li>\\(\\sigma\\) is the standard deviation of the data</li> <li>\\(k\\) is the step value, which can vary for each module or use the default step</li> </ul>","tags":["Z-Score","Interquartile Range"]},{"location":"blog/2023/10/12/data-outlier-detection-techniques/#interquartile-range-or-tukeys-fences-method","title":"Interquartile Range or Tukey\u2019s Fences Method","text":"<p>When <code>method</code> is set to \"IQR\", the function uses the interquartile range for outlier detection:</p> <ul> <li>The Interquartile Range (IQR) is the range between the 1st quartile (25th percentile) and the 3rd quartile (75th percentile) of the data.</li> </ul> \\[\\text{IQR} = Q3 - Q1\\] <p>Where:</p> <ul> <li>\\(Q1\\) is the 1st quartile (25th percentile)</li> <li>\\(Q3\\) is the 3rd quartile (75th percentile)</li> <li>To flag outliers, the function considers values that fall below the lower bound or above the upper bound:</li> </ul> \\[\\text{Lower bound} = Q1 - \\text{multiplier} \\times \\text{IQR}\\] \\[\\text{Upper bound} = Q3 + \\text{multiplier} \\times \\text{IQR}\\] <p>Where <code>multiplier</code> is a specified input parameter, often set to 1.5 for moderate outliers or 3 for extreme outliers. </p> <p>Any data value below the lower bound or above the upper bound is considered an outlier.</p> <p>quantile_limit:</p> <ul> <li>The <code>quantile_limit</code> determines the boundaries for the lower and upper quantiles.</li> <li>If set to a value like 0.25, then the lower and upper quantiles will be the 25th percentile (Q1) and the 75th percentile (Q3) respectively.</li> <li>This essentially defines the Interquantile Range which will be used in the next step to calculate the bounds for outliers. </li> </ul> <p>multiplier:</p> <ul> <li>Once the Interquantile Range (IQR) is calculated as \\(IQR = Q3 - Q1\\), the <code>multiplier</code> is used to determine how far above Q3 and below Q1 a data point needs to be in order to be considered an outlier.</li> <li>Specifically, the bounds for outliers are computed as:<ul> <li>Lower bound = \\(Q1 - (\\text{multiplier} \\times IQR)\\)</li> <li>Upper bound = \\(Q3 + (\\text{multiplier} \\times IQR)\\)</li> </ul> </li> <li>A common value for the <code>multiplier</code> in traditional statistics, when using the Interquartile Range method for outlier detection, is 1.5. However, this function allows the user to specify their own multiplier, offering flexibility in how aggressive or conservative they want the outlier detection to be. </li> <li>A higher multiplier will result in a broader range and fewer outliers, while a lower multiplier will create a narrower range and flag more points as outliers.</li> </ul> <p>Machine Learning-Based Methods:</p> <ul> <li> <p>Isolation Forest: Isolates outliers by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of the selected feature.</p> </li> <li> <p>One-Class SVM: Identifies outliers by classifying data points in a high-dimensional feature space using support vector machines.</p> </li> </ul> <p>Neighborhood-Based Methods:</p> <ul> <li> <p>K-Nearest Neighbors (K-NN): Detects outliers by measuring the distance of a point to its nearest neighbors.</p> </li> <li> <p>Local Outlier Factor (LOF): Identifies outliers by comparing the density of a point to the density of its neighbors.</p> </li> </ul> <p>Deep Learning Methods:</p> <ul> <li>Autoencoders: Identifies outliers by learning a low-dimensional representation of the data, then reconstructing the data and measuring reconstruction errors.</li> </ul> <p>The choice between normalization and raw data largely depends on the nature and distribution of the data.</p> <p>The choice between normalization and raw data largely depends on the nature and distribution of the data</p>","tags":["Z-Score","Interquartile Range"]},{"location":"blog/2023/10/12/data-outlier-detection-techniques/#use-cases-and-distinctions","title":"Use Cases, and Distinctions","text":"","tags":["Z-Score","Interquartile Range"]},{"location":"blog/2023/10/12/data-outlier-detection-techniques/#interquartile-range-iqr","title":"Interquartile Range (IQR)","text":"<ol> <li> <p>Nature: IQR measures the middle 50% of the data. It inherently accounts for the spread and central tendency of the data without making any assumptions about the data's distribution.</p> </li> <li> <p>Outliers: By design, IQR can detect outliers in data without requiring normalization, as it focuses on the range between quartiles that are less sensitive to extreme values.</p> </li> <li> <p>Usage: For data that has a skewed distribution, IQR can be particularly useful. Additionally, if data has multiple modes (multimodal), or in the presence of heavy tails, the IQR remains a robust method.</p> </li> </ol>","tags":["Z-Score","Interquartile Range"]},{"location":"blog/2023/10/12/data-outlier-detection-techniques/#standard-deviation-sd","title":"Standard Deviation (SD)","text":"<ol> <li> <p>Nature: Standard deviation is a measure of how spread out the numbers in a dataset are on average. It is sensitive to outliers.</p> </li> <li> <p>Assumptions: SD assumes that data has a nearly normal distribution. When applied to highly skewed data or data with significant outliers, the SD may not accurately capture the true spread of the data.</p> </li> <li> <p>Normalization: Given the sensitivity of SD to outliers and its assumptions about data distribution, normalization becomes crucial. Normalizing the data can make it more symmetrical and lessen the impact of extreme values, making the SD more representative of the true data variability.</p> </li> <li> <p>For example, using z-score normalization scales the data such that it has a mean of 0 and a standard deviation of 1. This helps ensure that the data conforms more closely to a standard normal distribution, making the use of SD for outlier detection more appropriate.</p> </li> </ol>","tags":["Z-Score","Interquartile Range"]},{"location":"blog/2023/10/12/data-outlier-detection-techniques/#when-to-use-iqr-without-normalization","title":"When to Use IQR Without Normalization?","text":"<ol> <li> <p>Skewed Data: If your dataset is skewed to the right or left, the IQR remains consistent as it focuses on the middle 50% of the data, making it less sensitive to extreme values.</p> </li> <li> <p>Heavy-tailed or Light-tailed Data: For distributions that have heavy tails (more frequent extreme values than the normal distribution) or light tails (less frequent extreme values), the IQR can be a robust measure.</p> </li> <li> <p>Multimodal Data: If your data has several peaks or modes, the IQR can still effectively measure the spread of the central data points.</p> </li> </ol> <p>In summary, while both IQR and SD are measures of data spread and can be used for outlier detection, their applicability and need for normalization vary based on the nature of the data. IQR is generally more robust to non-normal data distributions and outliers, while SD, particularly when used for outlier detection, often benefits from normalization to mitigate its sensitivity to extreme values.</p>","tags":["Z-Score","Interquartile Range"]},{"location":"blog/2023/10/12/data-outlier-detection-techniques/#conclusion","title":"Conclusion","text":"<p>In summary, while both IQR and SD are measures of data spread and can be used for outlier detection, their applicability and need for normalization vary based on the nature of the data. IQR is generally more robust to non-normal data distributions and outliers, while SD, particularly when used for outlier detection, often benefits from normalization to mitigate its sensitivity to extreme values.</p>","tags":["Z-Score","Interquartile Range"]},{"location":"contribution_guide/","title":"Contributing to Pharmbio Package","text":""},{"location":"contribution_guide/#welcome-contributors","title":"Welcome Contributors!","text":"<p>Thank you for considering contributing to the Pharmbio Package! We welcome contributions from everyone, and we are grateful for your interest in making our project better. This guide aims to provide you with all the information you need to contribute to the Pharmbio Package effectively.</p>"},{"location":"contribution_guide/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Contributing to Pharmbio Package</li> <li>Welcome Contributors!<ul> <li>Table of Contents</li> <li>Code of Conduct</li> <li>Getting Started</li> <li>How to Contribute</li> <li>Pull Request Process</li> <li>Coding Guidelines</li> <li>Reporting Bugs</li> <li>Feature Requests</li> <li>Community and Support</li> </ul> </li> </ul>"},{"location":"contribution_guide/#code-of-conduct","title":"Code of Conduct","text":"<p>Our project adheres to a Code of Conduct that all contributors are expected to follow. Please read the full text so that you can understand what actions will and will not be tolerated.</p>"},{"location":"contribution_guide/#getting-started","title":"Getting Started","text":"<p>To get started with contributing to our project, you should first: - Fork the repository on GitHub. - Clone your forked repository to your local machine. - Read our documentation to understand the project and its structure.</p>"},{"location":"contribution_guide/#how-to-contribute","title":"How to Contribute","text":"<p>There are many ways to contribute to the Pharmbio Package: - Fixing bugs or issues. - Developing new features. - Improving documentation or examples. - Reviewing Pull Requests.</p> <p>Before starting to work on a significant change, please open an issue to discuss it with maintainers. This way, we can ensure that your time is well spent and that your contributions align with the project's goals and standards.</p>"},{"location":"contribution_guide/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Ensure any install or build dependencies are removed before the end of the layer when doing a build.</li> <li>Update the README.md with details of changes, including new environment variables, exposed ports, useful file locations, and container parameters.</li> <li>Increase the version numbers in any examples files and the README.md to the new version that this Pull Request would represent.</li> <li>Submit a Pull Request to the original repository.</li> <li>The repository maintainers will review your Pull Request. Be patient, and respond to any feedback to expedite the process.</li> </ol>"},{"location":"contribution_guide/#coding-guidelines","title":"Coding Guidelines","text":"<ul> <li>Write clean, maintainable code and follow the existing coding conventions.</li> <li>Include comments and docstrings for your code.</li> <li>Add tests to cover new features or bug fixes.</li> <li>Make sure your code passes all existing tests.</li> </ul>"},{"location":"contribution_guide/#reporting-bugs","title":"Reporting Bugs","text":"<p>Use our issue tracker to report bugs. When creating a new issue, include: - A clear and descriptive title. - A detailed description of the bug. - Steps to reproduce the issue. - Expected and actual outcomes. - Screenshots or code snippets, if applicable.</p>"},{"location":"contribution_guide/#feature-requests","title":"Feature Requests","text":"<p>Feature requests are welcome. Open an issue to suggest new features or improvements, providing as much detail and context as possible.</p>"},{"location":"contribution_guide/#community-and-support","title":"Community and Support","text":"<p>Join our community channels in Slack for support, discussions, and updates about the Pharmbio Package. </p>"},{"location":"getting_started/","title":"Introduction","text":"<p>The <code>pharmbio</code> Python package serves as a toolkit developed for the Pharmaceutical Bioinformatics Research Group at Uppsala University, Sweden.</p> <p>Server Connection Dependency and Usage Constraints</p> <p>Please note that the <code>pharmbio</code> package is tightly integrated with the data server and file repository infrastructure of the Pharmaceutical Bioinformatics Research Group at Uppsala University. As such, it is not designed to function outside of this specific server workflow. The package is optimized for use within the group's ecosystem and its full range of functionalities are only accessible when connected to the group's server environment. Users should deploy and utilize <code>pharmbio</code> with this critical dependency in mind.</p>"},{"location":"getting_started/basic_usage/","title":"Basic Usage","text":""},{"location":"getting_started/basic_usage/#1-setting-the-database-uri-environment-variable","title":"1- Setting the Database URI Environment Variable","text":"<p>You have two options for setting the database URI as an environment variable:</p> <p>Using Jupyter Notebook's %env Magic Command</p> <p>If you are using Jupyter Notebook, you can use the <code>%env</code> magic command to set environment variables within your notebook:</p> <pre><code>%env DB_URI=your_database_uri_here\n</code></pre> <p>Using Python's <code>os</code> Library</p> <p>Alternatively, you can use Python's built-in <code>os</code> library to set the environment variable in your script or notebook:</p> <pre><code>import os\nos.environ[\"DB_URI\"] = \"your_database_uri_here\"\n</code></pre> <p>DB_URI</p> <p>For security reasons, the actual URI is not disclosed in this documentation. You will need to replace <code>your_database_uri_here</code> with the actual URI that you should have received from your system administrator or through internal protocols.</p>"},{"location":"getting_started/basic_usage/#2-accessing-image-quality-data","title":"2- Accessing Image Quality Data","text":"<p>After setting up your environment, the next step is to pull quality control data from the database. This is essential for pre-analysis steps, allowing you to validate the quality of your images before further processing. Here is a brief explanation of the code and its outputs for this part:</p> <pre><code>from pharmbio.dataset.image_quality import get_image_quality_ref, get_image_quality_data\n\n# Retrieve a reference DataFrame based on the study name\nqc_ref_df = get_image_quality_ref('AROS-Reproducibility-MoA-Full')\n\n# Get the actual quality control data based on the reference DataFrame\nqc_df = get_image_quality_data(qc_ref_df)\n</code></pre>"},{"location":"getting_started/basic_usage/#3-flagging-outlier-images","title":"3- Flagging Outlier Images","text":"<p>Once you have obtained the quality control data, you can flag outlier images based on pre-defined criteria. Outliers could be indicative of issues like focusing errors, staining inconsistencies, or other anomalies that may adversely affect the images. Here's how to flag these outliers using the <code>flag_outlier_images</code> function:</p> <pre><code>from pharmbio.data_processing.quality_control import flag_outlier_images\n\n# Flag outlier images based on the default setting\nflagged_qc_df = flag_outlier_images(qc_df)\n</code></pre>"},{"location":"getting_started/basic_usage/#4-retrieving-cell-morphology-data","title":"4- Retrieving Cell Morphology Data","text":"<p>You can also proceed to obtain cell morphology data for your study. This is crucial for downstream joining of two dataframes (cell phenotype and its image quality). Below is the code and its explanations:</p> <pre><code>from pharmbio.dataset.cell_morphology import get_cell_morphology_ref, get_cell_morphology_data\n\n# Retrieve a reference DataFrame based on the study name\ncp_ref_df = get_cell_morphology_ref(\"AROS-Reproducibility-MoA-Full\")\n\n# Get the actual cell morphology data based on the reference DataFrame\ncp_df = get_cell_morphology_data(cp_ref_df)\n</code></pre>"},{"location":"getting_started/basic_usage/#5-merging-image-quality-data-and-cell-morphology-data","title":"5- Merging Image Quality Data and Cell Morphology Data","text":"<p>To have final cell morphology dataframe simply you can pass quality control dataframe which you flagged in previous step to the <code>get_cell_morphology_data()</code> function and it will remove the flagged images:</p> <pre><code>cp_df = get_cell_morphology_data(cp_ref_df, flagged_qc_df)\n</code></pre>"},{"location":"getting_started/installation/","title":"Installation","text":""},{"location":"getting_started/installation/#from-terminal","title":"From Terminal","text":"<p>The <code>pharmbio</code> package is available on PyPI and can be easily installed using pip:</p> <pre><code>pip install pharmbio\n</code></pre> <p>To update the package to the latest version, use:</p> <pre><code>pip install -U pharmbio\n</code></pre> <p>Alternatively, you can install the package directly from our GitHub repository:</p> <pre><code>pip install git+https://github.com/pharmbio/pharmbio_package.git\n</code></pre>"},{"location":"getting_started/installation/#from-jupyter-notebook","title":"From Jupyter Notebook","text":"<p>If you want to install or update the package within a Jupyter Notebook, you have two options:</p> <p>1- Using !pip</p> <p>Run a cell with the following command:</p> <pre><code>!pip install pharmbio\n</code></pre> <p>2- Using %pip</p> <p>Alternatively, you can use the %pip magic command for a more environment-aware installation:</p> <pre><code>%pip install pharmbio\n</code></pre> <p>When using Jupyter notebook to install a package</p> <ul> <li>! is for shell commands that are unaware of your Python environment.</li> <li>% is for IPython magic commands that are often Python-aware.</li> </ul> <p>When you use <code>%pip</code> in a Jupyter Notebook, the package will be installed in the same Python environment where the Jupyter Notebook kernel is running. Using <code>%pip</code> ensures that you don't get confused about which Python environment you're installing the package into, especially useful when you have multiple Python environments on your system.</p>"},{"location":"release_notes/","title":"Pharmbio Package Release Notes","text":"<p>Welcome to the release notes for the Pharmbio Package. Below you will find detailed information about each version, including new features, improvements, and bug fixes. </p>"},{"location":"release_notes/#version-017-january-22-2024","title":"Version 0.1.7 - January 22, 2024","text":"<p>What's New: - [List new features or major improvements made in this version.]</p> <p>Bug Fixes: - [Detail any bug fixes or issues addressed in this version.]</p> <p>Miscellaneous: - [Any additional notes, such as performance improvements or minor changes.]</p>"},{"location":"release_notes/#version-016-october-5-2023","title":"Version 0.1.6 - October 5, 2023","text":"<p>What's New: - [Details of new features or major improvements.]</p> <p>Bug Fixes: - [Details of bug fixes or issues addressed.]</p> <p>Miscellaneous: - [Additional notes or minor changes.]</p>"},{"location":"release_notes/#version-015-september-7-2023","title":"Version 0.1.5 - September 7, 2023","text":"<p>Improvements: - [List of improvements or updates made in this version.]</p> <p>Bug Fixes: - [Details of bug fixes or issues resolved.]</p>"},{"location":"release_notes/#version-014-september-4-2023","title":"Version 0.1.4 - September 4, 2023","text":"<p>Enhancements: - [Details of enhancements or additional functionality.]</p> <p>Bug Fixes: - [Details of bug fixes or issues fixed.]</p>"},{"location":"release_notes/#version-013-august-31-2023","title":"Version 0.1.3 - August 31, 2023","text":"<p>Updates: - [List of updates or changes made in this version.]</p> <p>Bug Fixes: - [Details of bug fixes or issues addressed.]</p>"},{"location":"release_notes/#version-012-august-30-2023","title":"Version 0.1.2 - August 30, 2023","text":"<p>Improvements: - [Details of improvements or updates.]</p>"},{"location":"release_notes/#version-011-august-30-2023","title":"Version 0.1.1 - August 30, 2023","text":"<p>Minor Fixes: - [Details of minor fixes or adjustments.]</p>"},{"location":"release_notes/#version-010-july-13-2023","title":"Version 0.1.0 - July 13, 2023","text":"<p>Initial Release: - [Overview of the initial release, including key features and capabilities.]</p> <p>For more detailed information on each release, including technical details and documentation, please visit our GitHub repository</p>"},{"location":"user_guide/","title":"User Guide","text":"<p>Welcome to the user guide section of the <code>pharmbio</code> documentation. This part of the guide is aimed at users who are familiar with the basic functionalities and are looking to explore its more in-depth features and capabilities. Whether you're looking to optimize your workflows, integrate our package into larger projects, or simply explore the full depth of what our package has to offer, you'll find the insights and examples here.</p>"},{"location":"user_guide/avanced_usage/","title":"Avanced Usage","text":""},{"location":"user_guide/avanced_usage/#looking-up-the-experiment-in-the-database-with-name","title":"Looking up the experiment in the database with name","text":"<p>Certainly, here's the concise version of the tutorial focusing on the usage of <code>get_projects_list()</code>:</p>"},{"location":"user_guide/avanced_usage/#using-get_projects_list","title":"Using <code>get_projects_list()</code>","text":""},{"location":"user_guide/avanced_usage/#basic-usage-retrieving-all-projects","title":"Basic Usage - Retrieving All Projects","text":"<p>To fetch the complete list of project names without any filters, simply call the function without passing any arguments. This is useful for getting an overview of all available projects in the database.</p> <pre><code>project_list = get_projects_list()\nprint(project_list)\n</code></pre> <p>Output Example: <code>['Project A', 'Project B', 'Project C', ...]</code></p>"},{"location":"user_guide/avanced_usage/#filtered-search-using-the-lookup-parameter","title":"Filtered Search - Using the <code>lookup</code> Parameter","text":"<p>For more refined searches, use the <code>lookup</code> parameter. This is particularly helpful when dealing with large datasets where you need to find projects related to a specific topic or keyword.</p> <pre><code>filtered_list = get_projects_list(lookup='aros')\nprint(filtered_list)\n</code></pre> <p>Output Example: <code>['AROS-CP', 'AROS-Reproducibility-MoA-Full', ...]</code></p> <p>Note</p> <p>The search is case-insensitive and can match partial strings.</p>"},{"location":"user_guide/avanced_usage/#accessing-image-quality-data","title":"Accessing Image Quality Data","text":""},{"location":"user_guide/avanced_usage/#using-get_image_quality_ref-with-advanced-filtering","title":"Using <code>get_image_quality_ref()</code> with Advanced Filtering","text":""},{"location":"user_guide/avanced_usage/#introduction","title":"Introduction","text":"<p>The <code>get_image_quality_ref()</code> function, part of the <code>pharmbio.dataset.image_quality</code> module, is essential for retrieving quality control reference data from specific studies. This tutorial covers its advanced usage, particularly focusing on complex filtering techniques to refine the data retrieval process.</p>"},{"location":"user_guide/avanced_usage/#step-by-step-guide","title":"Step-by-Step Guide","text":"<ol> <li>Basic Retrieval without Replication Dropping    Initially, you can retrieve all replications (including duplicates) by setting the <code>drop_replication</code> parameter to <code>\"None\"</code>. This will return every instance, replicated analysis IDs included.    <pre><code>qc_ref_df = get_image_quality_ref(\"sarscov2-repurposing\", drop_replication=\"None\")\nprint(qc_ref_df)\n</code></pre></li> <li>Filtering by Date    To focus on experiments conducted in a specific year, use the <code>filter</code> parameter. For instance, to view experiments from 2021:    <pre><code>qc_ref_df = get_image_quality_ref(\n    \"sarscov2-repurposing\",\n    drop_replication=\"None\",\n    filter={\"analysis_date\": [\"2021\"]},\n)\nprint(qc_ref_df)\n</code></pre></li> <li>Combining Multiple Filters    You can combine filters to further refine your search. For example, to view experiments from both 2021 and 2023:    <pre><code>qc_ref_df = get_image_quality_ref(\n    \"sarscov2-repurposing\",\n    drop_replication=\"None\",\n    filter={\"analysis_date\": [\"2021\", \"2023\"]},\n)\nprint(qc_ref_df)\n</code></pre></li> <li>Filtering by Specific Criteria    To get data from 2023 that used VeroE6 cells, add another key to the filter:    <pre><code>qc_ref_df = get_image_quality_ref(\n    \"sarscov2-repurposing\",\n    drop_replication=\"None\",\n    filter={\"analysis_date\": [\"2023\"], \"plate_barcode\": [\"VeroE6\"]},\n)\nprint(qc_ref_df)\n</code></pre></li> <li>Advanced Filtering with Partial Matches    For more specific searches, like filtering by a part of a string, you can include partial strings in the filter. For example, to find data with <code>plate_acq_id</code> starting with \"37\":    <pre><code>qc_ref_df = get_image_quality_ref(\n    \"sarscov2-repurposing\",\n    drop_replication=\"None\",\n    filter={\n        \"analysis_date\": [\"2023\"],\n        \"plate_barcode\": [\"VeroE6\"],\n        \"plate_acq_id\": [\"37\"],\n    },\n)\nprint(qc_ref_df)\n</code></pre></li> </ol> <p>Note</p> <ul> <li>Flexible Filtering: The <code>filter</code> argument accepts multiple keys and values. Values should be in list format and can be partial strings.</li> <li>String-Based Filtering: Even numerical values should be passed as strings to enable partial matching.</li> <li>Combining Filters: Filters act conjunctively, allowing for precise data retrieval based on multiple criteria.</li> </ul>"},{"location":"user_guide/avanced_usage/#flagging-outlier-images","title":"Flagging Outlier Images","text":""},{"location":"user_guide/avanced_usage/#advanced-functions-in-pharmbiodata_processingquality_control","title":"Advanced Functions in <code>pharmbio.data_processing.quality_control</code>","text":""},{"location":"user_guide/avanced_usage/#introduction_1","title":"Introduction","text":"<p>The <code>pharmbio.data_processing.quality_control</code> module in Python provides an extensive set of functions for handling and analyzing image quality control data in biomedical research. This tutorial will cover the advanced functionalities of this module, specifically focusing on functions such as <code>get_qc_module</code>, <code>get_qc_data_dict</code>, <code>get_channels</code>, and <code>flag_outlier_images</code>.</p>"},{"location":"user_guide/avanced_usage/#1-get_qc_module","title":"1. <code>get_qc_module</code>","text":"<p>Purpose: To extract and return a sorted list of image quality module names from the quality control data.</p> <p>Usage Example:</p> <pre><code>qc_data = get_image_quality_data(name='example')\nqc_modules = get_qc_module(qc_data)\nprint(qc_modules)\n</code></pre>"},{"location":"user_guide/avanced_usage/#2-get_qc_data_dict","title":"2. <code>get_qc_data_dict</code>","text":"<p>Purpose: To create a dictionary of image quality module data frames, filtered by specified modules to keep or drop.</p> <p>Usage Example:</p> <pre><code>qc_data = pd.DataFrame({\n    'ImageQuality_FocusScore': [0.5, 0.6, 0.7],\n    'ImageQuality_Intensity': [0.8, 0.9, 1.0],\n    'OtherColumn': [1, 2, 3]\n})\nqc_data_dict = get_qc_data_dict(qc_data, module_to_keep={'FocusScore'})\nprint(qc_data_dict)\n</code></pre>"},{"location":"user_guide/avanced_usage/#3-get_channels","title":"3. <code>get_channels</code>","text":"<p>Purpose: To return a dictionary of channels and sub-channels for each QC module in the QC data.</p> <p>Usage Example:</p> <pre><code>qc_data = pd.DataFrame({\n    'ImageQuality_FocusScore_CONC': [0.5, 0.6, 0.7],\n    'ImageQuality_FocusScore_HOECHST': [0.8, 0.9, 1.0],\n    'ImageQuality_Intensity_CONC': [1, 2, 3],\n    'OtherColumn': ...\n})\nchannels = get_channels(qc_data)\nprint(channels)\n</code></pre>"},{"location":"user_guide/avanced_usage/#4-flag_outlier_images","title":"4. <code>flag_outlier_images</code>","text":"<p>Purpose: To flag outlier images based on specified quality control data using either Standard Deviation (SD) or Interquartile Range (IQR) methods.</p> <p>Usage Example:</p>"},{"location":"user_guide/avanced_usage/#deep-dive-into-flag_outlier_images-function","title":"Deep Dive into <code>flag_outlier_images</code> Function","text":"<p>The <code>flag_outlier_images</code> function in the <code>pharmbio.data_processing.quality_control</code> module is designed to flag outlier images in a dataset based on certain statistical methods. It's a sophisticated function that allows for nuanced control over the outlier detection process. Let's break it down and examine its components and usage.</p>"},{"location":"user_guide/avanced_usage/#function-parameters","title":"Function Parameters","text":"<ol> <li> <p>method (Literal[\"SD\", \"IQR\"]): The outlier detection method, either Standard Deviation (\"SD\") or Interquartile Range (\"IQR\").</p> </li> <li> <p>IQR_normalization (bool): Determines whether to normalize the data when using the IQR method.</p> </li> <li> <p>normalization (Literal[\"zscore\", \"minmax\"]): The type of normalization to apply, either z-score or min-max normalization.</p> </li> <li> <p>sd_step_dict (Dict[str, Tuple[float, float]]): A dictionary specifying the SD steps for each module.</p> </li> <li> <p>default_sd_step (Tuple[float, float]): Default SD steps if <code>sd_step_dict</code> is not provided.</p> </li> <li> <p>quantile_limit (float): The quantile limit for the IQR method.</p> </li> <li> <p>multiplier (float): The multiplier for the IQR method.</p> </li> </ol>"},{"location":"user_guide/avanced_usage/#examples-of-usage","title":"Examples of Usage","text":"<ol> <li>Basic Usage with SD Method: <pre><code>qc_data = get_image_quality_data(name='example')\nflagged_data = flag_outlier_images(qc_data, method='SD')\n</code></pre></li> <li>Using IQR Method with Specific Modules: <pre><code>flagged_data = flag_outlier_images(\n qc_data,\n module_to_keep={'FocusScore', 'Intensity'},\n method='IQR',\n multiplier=1.5)\n</code></pre></li> <li>Applying Custom SD Range for Specific Modules: <pre><code>sd_step_dict = {'FocusScore': (-3, 3), 'Intensity': (-2, 2)}\nflagged_data = flag_outlier_images(qc_data, method='SD', sd_step_dict=sd_step_dict)\n</code></pre></li> <li>Combining Module Filtering and Normalization: <pre><code>flagged_data = flag_outlier_images(\n qc_data, module_to_keep={'FocusScore'},\n module_to_drop={'Intensity'},\n normalization='minmax',\n method='SD')\n</code></pre></li> </ol> <p>Note</p> <ul> <li>Flexibility: These functions provide flexibility in processing and analyzing QC data by allowing the selection of specific modules and methods for outlier detection.</li> <li>Customization: You can customize the filtering process with <code>module_to_keep</code> and <code>module_to_drop</code> to target specific QC modules.</li> <li>Outlier Detection: <code>flag_outlier_images</code> offers robust outlier detection with options for normalization and threshold setting.</li> </ul>"},{"location":"user_guide/avanced_usage/#retrieving-cell-morphology-data","title":"Retrieving Cell Morphology Data","text":""},{"location":"user_guide/avanced_usage/#exploring-the-pharmbiodatasetcell_morphology-module","title":"Exploring the <code>pharmbio.dataset.cell_morphology</code> Module","text":"<p>The <code>pharmbio.dataset.cell_morphology</code> module provides a suite of functions specifically designed to handle and query cell morphology data. Each function serves a unique purpose, catering to various aspects of data handling, from retrieval and outlier detection to data aggregation. Let's delve into the details of these functions.</p>"},{"location":"user_guide/avanced_usage/#1-get_cell_morphology_ref","title":"1. <code>get_cell_morphology_ref()</code>","text":"<ul> <li>Purpose: Retrieves cell morphology references from a database, allowing users to specify a reference name and apply filtering.</li> <li>Parameters:</li> <li><code>name</code>: A mandatory parameter specifying the reference name.</li> <li><code>filter</code>: An optional dictionary for filtering the query.</li> <li>Usage Example: <pre><code>name = \"example_reference\"\nfilter = {\"column1\": [\"value_1\", \"value2\"], \"column2\": [\"value3\"]}\nfiltered_df = get_cell_morphology_ref(name, filter)\ndisplay(filtered_df)\n</code></pre></li> <li>Key Point: This function is crucial for extracting specific cell morphology data and supports complex query constructions using filters.</li> </ul>"},{"location":"user_guide/avanced_usage/#2-get_outlier_df","title":"2. <code>get_outlier_df()</code>","text":"<ul> <li>Purpose: Retrieves a DataFrame containing detailed information about outliers from flagged QC data.</li> <li>Parameters:</li> <li><code>flagged_qc_df</code>: A DataFrame containing flagged QC data.</li> <li><code>with_compound_info</code>: Optionally includes compound-related information.</li> <li>Usage Example: <pre><code>flagged_qc_df = # Pre-existing DataFrame with flagged QC data\noutlier_df = get_outlier_df(flagged_qc_df)\nprint(outlier_df)\n</code></pre></li> <li>Key Point: This function is essential for detailed outlier analysis in cell morphology studies, offering an optional inclusion of compound information.</li> </ul>"},{"location":"user_guide/avanced_usage/#3-get_comp_outlier_info","title":"3. <code>get_comp_outlier_info()</code>","text":"<ul> <li>Purpose: Computes and provides detailed information about outliers in a dataset.</li> <li>Parameters:</li> <li><code>flagged_df</code>: A DataFrame with flagged data, including batch identification and outlier flags.</li> <li>Usage Example: <pre><code>flagged_df = # Pre-existing DataFrame with flagged data\noutlier_info_df = get_comp_outlier_info(flagged_df)\n</code></pre></li> <li>Key Point: It's vital for understanding the impact of outliers on data, particularly useful in large-scale studies involving numerous compounds.</li> </ul>"},{"location":"user_guide/avanced_usage/#4-get_cell_morphology_data","title":"4. <code>get_cell_morphology_data()</code>","text":"<ul> <li>Purpose: Aggregates cell morphology data from various sources, incorporating user-defined parameters for detailed analysis.</li> <li>Parameters:<ul> <li><code>cell_morphology_ref_df</code>: The main DataFrame containing cell morphology data.</li> <li><code>flagged_qc_df</code>: (Optional) DataFrame with flagged QC data to identify outliers.</li> <li><code>site_threshold</code>: Numeric threshold for flagged sites in a well.</li> <li><code>compound_threshold</code>: Numeric threshold for percentage of data loss.</li> <li><code>aggregation_level</code>: Level of data aggregation (e.g., \"cell\", \"well\").</li> <li><code>aggregation_method</code>: Methods for aggregation (e.g., \"mean\", \"median\").</li> <li><code>path_to_save</code>: Path to save the aggregated data.</li> <li><code>use_gpu</code>: Option to use GPU for faster processing.</li> <li><code>save_plate_separately</code>: Whether to save data for each plate separately.</li> </ul> </li> <li>Data Integration: It combines reference cell morphology data (<code>cell_morphology_ref_df</code>) with quality control data (<code>flagged_qc_df</code>), if provided.</li> <li>Threshold-Based Outlier Handling: The function allows for the exclusion of data based on the number of flagged sites in a well (<code>site_threshold</code>) and the percentage of data loss at which a compound is flagged (<code>compound_threshold</code>).</li> <li> <p>Flexible Aggregation: Aggregates data at specified levels (<code>aggregation_level</code>) like cell, site, well, plate, or compound, using various methods (<code>aggregation_method</code>).</p> </li> <li> <p>Usage Example:</p> <ol> <li>Basic Aggregation at the Cell Level:    Aggregates data at the cell level without considering outliers.    <pre><code>cell_morphology_ref_df = get_cell_morphology_ref(\"example_reference\")\naggregated_df = get_cell_morphology_data(cell_morphology_ref_df, aggregation_level='cell')\ndisplay(aggregated_df)\n</code></pre></li> <li>Aggregation with Outlier Data at the Well Level:    Uses flagged QC data to remove outlier wells before aggregation.    <pre><code>flagged_qc_df = # Assume pre-existing DataFrame with flagged QC data\naggregated_df = get_cell_morphology_data(\n    cell_morphology_ref_df,\n    flagged_qc_df,\n    site_threshold=5,  # Wells with more than 5 flagged sites are removed\n    aggregation_level='well'\n)\ndisplay(aggregated_df)\n</code></pre></li> <li>Aggregation with Compound Deletion Threshold:    Removes compounds with a high percentage of data loss.    <pre><code>aggregated_df = get_cell_morphology_data(\n    cell_morphology_ref_df,\n    flagged_qc_df,\n    compound_threshold=0.6,  # Compounds with more than 60% data loss are removed\n    aggregation_level='compound'\n)\ndisplay(aggregated_df)\n</code></pre></li> <li>Custom Aggregation Method:    Aggregates data using a custom method, such as median, for each level.    <pre><code>aggregation_method = {\"cell\": \"median\", \"well\": \"median\", \"plate\": \"median\"}\naggregated_df = get_cell_morphology_data(\n    cell_morphology_ref_df,\n    aggregation_level='plate',\n    aggregation_method=aggregation_method\n)\ndisplay(aggregated_df)\n</code></pre></li> <li>Utilizing GPU Acceleration:    Aggregates data using GPU acceleration for large datasets.    <pre><code>aggregated_df = get_cell_morphology_data(\n    cell_morphology_ref_df,\n    use_gpu=True,\n    aggregation_level='plate'\n)\ndisplay(aggregated_df)\n</code></pre></li> </ol> </li> </ul>"},{"location":"user_guide/avanced_usage/#conclusion","title":"Conclusion","text":"<p><code>get_cell_morphology_data</code> offers versatile solutions for cell morphology data analysis. Its ability to integrate different data sources, handle outliers based on user-defined thresholds, and perform custom aggregation makes it a valuable tool for researchers. By selecting appropriate parameters, you can tailor the function to meet the specific needs of your study, ensuring efficient and meaningful data analysis.</p> <p>Note</p> <pre><code>- This function is a comprehensive tool for cell morphology data management, offering flexibility in handling outlier data and custom aggregation methods.\n</code></pre>"},{"location":"user_guide/avanced_usage/#explanation-of-the-experiment-class","title":"Explanation of the <code>Experiment</code> Class","text":"<p>The <code>Experiment</code> class is a tool designed for automating the process of handling and analyzing cell morphology and image quality data in the <code>pharmbio</code> package. It integrates various functions from the <code>pharmbio.dataset.cell_morphology</code> and <code>pharmbio.dataset.image_quality</code> modules, streamlining data processing tasks. The class is initialized with parameters defined in a JSON file, providing an easy and customizable approach to experiment management.</p>"},{"location":"user_guide/avanced_usage/#class-overview","title":"Class Overview","text":"<ul> <li>Initialization: The class is instantiated with a JSON file that includes experiment settings, such as <code>experiment_name</code>, <code>filter</code>, <code>module_to_keep</code>, etc.</li> <li>Attributes: The class maintains several attributes related to image quality, cell morphology, outlier detection, and aggregation.</li> <li>Methods: It includes methods for retrieving and processing data, aggregating results, and generating visualizations.</li> </ul>"},{"location":"user_guide/avanced_usage/#key-methods","title":"Key Methods","text":"<ol> <li> <p>Data Retrieval Methods:</p> <ul> <li><code>get_image_quality_reference_data()</code>: Retrieves image quality reference data.</li> <li><code>get_cell_morphology_reference_data()</code>: Retrieves cell morphology reference data.</li> </ul> </li> <li> <p>Data Processing Methods:</p> <ul> <li><code>get_image_quality_data()</code>: Processes image quality data.</li> <li><code>get_cell_morphology_data()</code>: Processes and aggregates cell morphology data.</li> </ul> </li> <li> <p>Outlier Analysis Methods:</p> <ul> <li><code>flag_outlier_images()</code>: Flags outlier images in the dataset.</li> <li><code>get_image_guality_modules()</code>, <code>get_image_guality_data_dict()</code>: Retrieve and organize image quality data.</li> </ul> </li> <li> <p>Visualization Methods:</p> <ul> <li><code>plate_heatmap()</code>, <code>well_outlier_heatmap()</code>, <code>quality_module_lineplot()</code>: Generate various plots for data visualization.</li> </ul> </li> <li> <p>Utility Methods:</p> <ul> <li><code>print_setting()</code>: Prints the current settings of the experiment.</li> </ul> </li> </ol>"},{"location":"user_guide/avanced_usage/#json-file-structure","title":"JSON File Structure","text":"<p>The JSON file serves as the configuration for the experiment. It specifies parameters like:</p> <ul> <li><code>experiment_name</code>: The name of the experiment.</li> <li><code>filter</code>: Conditions for data filtering.</li> <li><code>force_merging_columns</code>: Handling of merging columns.</li> <li><code>module_to_keep</code>: Modules to include in analysis.</li> <li><code>method</code>: Method for outlier detection.</li> <li><code>site_threshold</code>, <code>compound_threshold</code>: Thresholds for data exclusion.</li> <li><code>aggregation_level</code>: Level of data aggregation.</li> </ul>"},{"location":"user_guide/avanced_usage/#usage-example","title":"Usage Example","text":"<p>With the provided JSON file which is just values for the arguments that exist in different function used above we can initiate a class instant that include all data and plot for specific experiment:</p> <pre><code>{\n    \"experiment_name\": \"AROS-Reproducibility-MoA-Full\",\n    \"filter\": {\n        \"analysis_id\": [\n            \"3248\",\n            \"3249\"\n        ]\n    },\n    \"force_merging_columns\": \"keep\",\n    \"module_to_keep\": [\n        \"FocusScore\",\n        \"MaxIntensity\",\n        \"MeanIntensity\",\n        \"PowerLogLogSlope\",\n        \"StdIntensity\"\n    ],\n    \"method\": \"SD\",\n    \"site_threshold\": 4,\n    \"compound_threshold\": 0.7,\n    \"aggregation_level\": \"cell\"\n}\n</code></pre> <p>This JSON file serves as a configuration for initializing the <code>Experiment</code> class, detailing the parameters for the experiment's data processing and analysis. An <code>Experiment</code> object can be created and used to automate data retrieval, processing, and analysis tasks:</p> <pre><code>experiment = Experiment(json_file=\"path_to_json_file.json\")\n</code></pre> <p>Using the methods and attributes of the <code>Experiment</code> class, one can perform a comprehensive analysis of the experiment data, from quality control to cell morphology analysis, and visualize the results efficiently.</p> <p>JSON File Composition</p> <ol> <li>Specify Mandatory Fields:<ul> <li>Always include <code>experiment_name</code> as it's essential for identifying the dataset.</li> </ul> </li> <li>Optional Fields:<ul> <li>Fields like <code>filter</code>, <code>module_to_keep</code>, and others are optional. If not provided, the class will use default values or behaviors.</li> </ul> </li> <li>Using Filters and Selections:<ul> <li>Define filters (e.g., <code>filter</code>) and module selections (<code>module_to_keep</code>) as arrays, even if only one value is needed.</li> </ul> </li> <li>Setting Thresholds and Parameters:<ul> <li>Include parameters like <code>site_threshold</code> and <code>compound_threshold</code> to customize data processing. Absence of these will result in the use of default thresholds.</li> </ul> </li> </ol> <p>Class Behavior and Default Settings</p> <ol> <li>Default Values:<ul> <li>When a variable is not specified in the JSON, the class uses predefined default values. For example, the default for <code>site_threshold</code> might be set to 6 if not specified.</li> </ul> </li> <li>Flexible Data Handling:<ul> <li>The class can handle various scenarios, such as missing data or unspecified parameters, by resorting to default processing methods or skipping certain steps.</li> </ul> </li> <li>Error Handling:<ul> <li>Ensure proper formatting and valid values in the JSON file to prevent runtime errors. For instance, numeric fields should not contain non-numeric characters.</li> </ul> </li> <li>Modular Approach:<ul> <li>Each method within the class is responsible for a specific aspect of the experiment's data processing. This modular design facilitates troubleshooting and customization.</li> </ul> </li> </ol>"},{"location":"user_guide/avanced_usage/#conclusion_1","title":"Conclusion","text":"<p>The <code>Experiment</code> class, when used with a well-structured JSON configuration file, provides a powerful and flexible way to automate and manage data processing tasks in cell morphology and image quality analysis. By adhering to these guidelines, researchers can efficiently configure and execute their experiments with greater control and customization.</p>"},{"location":"user_guide/configuration/","title":"Configuration","text":"<p>After successfully installing <code>pharmbio</code>, the next essential step is configuring your environment to ensure seamless interaction with the necessary resources. Before using the package, it's imperative to set the database URI as an environment variable. This configuration is crucial as the package requires a connection to the image database. The proper setup of the database URI ensures that your instance of <code>pharmbio</code> is connected to the correct server, allowing you to fully utilize its features and functionalities.</p>"},{"location":"user_guide/configuration/#setting-the-database-uri-environment-variable","title":"Setting the Database URI Environment Variable","text":"<p>You have two options for setting the database URI as an environment variable:</p> <p>Using Jupyter Notebook's %env Magic Command</p> <p>If you are using Jupyter Notebook, you can use the <code>%env</code> magic command to set environment variables within your notebook:</p> <pre><code>%env DB_URI=your_database_uri_here\n</code></pre> <p>Info</p> <p>Note that in this method you must avoid quotation and use the URI without putting it in ' or \"!</p> <p>Using Python's <code>os</code> Library</p> <p>Alternatively, you can use Python's built-in <code>os</code> library to set the environment variable in your script or notebook:</p> <pre><code>import os\nos.environ[\"DB_URI\"] = \"your_database_uri_here\"\n</code></pre> <p>DB_URI</p> <p>For security reasons, the actual URI is not disclosed in this documentation. You will need to replace <code>your_database_uri_here</code> with the actual URI that you should have received from system administrator or through internal protocols.</p>"},{"location":"user_guide/configuration/#setting-environment-variables-in-the-operating-system","title":"Setting Environment Variables in the Operating System","text":"<p>Another method to set the database URI environment variable for [Your Package Name] is by directly configuring it in your operating system. This approach is particularly useful when you want the environment variable to be globally accessible across various applications and scripts, or when you prefer not to include environment-specific code in your Python scripts or Jupyter Notebooks.</p>"},{"location":"user_guide/configuration/#for-windows","title":"For Windows:","text":"<ol> <li> <p>Using System Properties:</p> <ul> <li>Open the Start Search, type \"Environment Variables\" and select \"Edit the system environment variables.\"</li> <li>In the System Properties window, click on \"Environment Variables.\"</li> <li>Under \"User variables\" or \"System variables,\" click \"New\" to create a new environment variable.</li> <li>Enter <code>DB_URI</code> as the variable name and your database URI in the variable value field.</li> <li>Click OK to save the changes. You might need to restart your system or the command prompt to apply these changes.</li> </ul> </li> <li> <p>Using Command Line with <code>setx</code> Command:</p> <ul> <li>Open Command Prompt and use the <code>setx</code> command:     <pre><code>setx DB_URI \"your_database_uri_here\"\n</code></pre></li> <li>This command sets the <code>DB_URI</code> environment variable to your database URI. The changes will apply from the next session of the Command Prompt.</li> </ul> </li> </ol>"},{"location":"user_guide/configuration/#for-unixlinux","title":"For Unix/Linux:","text":"<ul> <li>Using Shell Configuration Files:<ul> <li>Edit your shell configuration file (like <code>.bashrc</code>, <code>.bash_profile</code>, <code>.profile</code>, or <code>.zshrc</code> for macOS) in your home directory.</li> <li>Add the following line at the end of the file:     <pre><code>export DB_URI=\"your_database_uri_here\"\n</code></pre></li> <li>Save the file and source it to apply the changes immediately:     <pre><code>source ~/.bashrc\n</code></pre></li> <li>These changes will be applied the next time you log in.</li> </ul> </li> </ul> <p>Advantages of Setting Environment Variables in the OS</p> <ul> <li>Global Access: Variables set in this way are accessible by all Python scripts and applications running under your user account, providing a consistent environment across your work.</li> <li>Security: Keeping sensitive information like database URIs out of your source code enhances security, especially when your code is shared or stored in version control systems.</li> <li>Flexibility: This method allows for different configurations across various environments (development, testing, production) by simply changing the environment variables in each respective system.</li> </ul> <p>Important Considerations</p> <ul> <li>Privacy and Security: Be cautious about setting sensitive data as global environment variables, especially on shared or public machines.</li> <li>Session Persistence: For Unix/Linux, changes made in shell configuration files are persistent across sessions. In contrast, using <code>setx</code> in Windows or setting variables in a terminal session (without editing configuration files) typically affects only the current session or new sessions, respectively.</li> <li>System Access: Modifying system-level environment variables may require administrative privileges.</li> </ul> <p>By setting the <code>DB_URI</code> environment variable directly in the operating system, you create a stable and secure configuration foundation for <code>pharmbio</code>, ensuring it operates seamlessly with the necessary database connections across different execution environments.</p>"},{"location":"user_guide/configuration/#choose-the-right-server-as-your-workspace","title":"Choose the right server as your workspace","text":"<p><code>Pharmbio</code>'s infrastructure comprises multiple servers, each serving different purposes. It is vital to ensure that your workspace is located on the correct server to access the necessary file repositories. This is especially crucial for retrieving cell painting data, which is essential for <code>Pharmbio</code>'s functionality.</p> <p>Is Your Workspace on the Correct Server for Accessing File Repositories?</p> <p>The package relies on specific directories that may only be available on certain servers. If you are uncertain about whether your workspace is on the appropriate server, or if you find that you do not have access to the required data, please contact server administrators. They can assist in relocating your workspace to the correct server or provide the necessary access rights, ensuring that you can work effectively with <code>Pharmbio</code>.</p>"},{"location":"user_guide/default_usage/","title":"Default Usage","text":""},{"location":"user_guide/default_usage/#looking-up-the-experiment-in-the-database-with-name","title":"Looking up the experiment in the database with name","text":"<p>The <code>get_projects_list</code> function in the <code>pharmbio.dataset.experiment</code> module is designed for easy retrieval of project lists from your database. It's a straightforward function that can be used to get a complete list of projects or to filter them based on a keyword.</p> <p>To use the function, simply call it without any arguments to get a full list of projects:</p> <pre><code>from pharmbio.dataset.experiment import get_projects_list\n\nall_projects = get_projects_list()\nprint(all_projects)\n</code></pre> <p>If you need to filter the list, provide a keyword to the <code>lookup</code> parameter. This search is not case-sensitive and will return any project that contains the keyword, regardless of its position in the name.</p> <p>Example with a lookup filter:</p> <pre><code>filtered_list = get_projects_list(lookup='aros')\nprint(filtered_list)\n# Output might include projects like 'AROS-CP', 'AROS-Reproducibility-MoA-Full'\n</code></pre>"},{"location":"user_guide/default_usage/#accessing-image-quality-data","title":"Accessing Image Quality Data","text":"<p>After finding the full name of the experiment, the next step is to pull quality control data from the database. This is essential for pre-analysis steps, allowing you to validate the quality of your images before further processing. Here is how you do this:</p> <pre><code>from pharmbio.dataset.image_quality import get_image_quality_ref, get_image_quality_data\n\n# Retrieve a reference DataFrame based on the study name\nqc_ref_df = get_image_quality_ref('AROS-Reproducibility-MoA-Full')\n\n# Get the actual quality control data based on the reference DataFrame\nqc_df = get_image_quality_data(qc_ref_df)\n</code></pre>"},{"location":"user_guide/default_usage/#flagging-outlier-images","title":"Flagging Outlier Images","text":"<p>Once you have obtained the quality control data, you can flag outlier images based on pre-defined criteria. Outliers could be indicative of issues like focusing errors, staining inconsistencies, or other anomalies that may adversely affect the images. This step will just add some extra columns to dataframe which indicate which image (row) has poor quality. Here's how to flag these outliers using the <code>flag_outlier_images</code> function:</p> <pre><code>from pharmbio.data_processing.quality_control import flag_outlier_images\n\n# Flag outlier images based on the default setting\nflagged_qc_df = flag_outlier_images(qc_df)\n</code></pre>"},{"location":"user_guide/default_usage/#retrieving-cell-morphology-data","title":"Retrieving Cell Morphology Data","text":"<p>You can also proceed to obtain cell morphology data for your study. This is crucial for downstream joining of two dataframes (cell phenotype and its flagged image quality). This is how you do this:</p> <pre><code>from pharmbio.dataset.cell_morphology import get_cell_morphology_ref, get_cell_morphology_data\n\n# Retrieve a reference DataFrame based on the study name\ncp_ref_df = get_cell_morphology_ref(\"AROS-Reproducibility-MoA-Full\")\n\n# Get the actual cell morphology data based on the reference DataFrame\ncp_df = get_cell_morphology_data(cp_ref_df)\n</code></pre>"},{"location":"user_guide/default_usage/#merging-image-quality-data-and-cell-morphology-data","title":"Merging Image Quality Data and Cell Morphology Data","text":"<p>To have final cell morphology dataframe simply you can pass quality control dataframe which you flagged in previous step to the <code>get_cell_morphology_data()</code> function and it will remove the flagged images:</p> <pre><code>cp_df = get_cell_morphology_data(cp_ref_df, flagged_qc_df)\n</code></pre>"},{"location":"user_guide/api/","title":"Pharmbio API Reference","text":"<p>This part of the documentation is crafted to provide you with in-depth information on each module, function, and class within Pharmbio. Whether you are integrating complex data processing tasks, visualizing results, or managing datasets and databases, this reference is your key to unlocking the full potential of Pharmbio.</p>"},{"location":"user_guide/api/#explore-our-api-sections","title":"Explore Our API Sections","text":"<p>Dive into the specifics of each module and discover how to leverage their capabilities in your projects:</p> <ul> <li>Config</li> <li>Logger</li> <li>Utils</li> <li>Data Processing</li> <li>Database</li> <li>Dataset</li> <li>Visualization</li> </ul>"},{"location":"user_guide/api/#integration-and-troubleshooting","title":"Integration and Troubleshooting","text":"<ul> <li>Integration</li> <li>Troubleshooting</li> </ul>"},{"location":"user_guide/api/config/","title":"Config","text":"<p>This Python configuration file (<code>config.py</code>) is part of the <code>pharmbio</code>, designed for managing various settings and parameters related to logging, database connections, data schemas, and quality control in a biomedical or pharmaceutical research context.</p>"},{"location":"user_guide/api/config/#logging-level-setting","title":"Logging Level Setting","text":"<ul> <li>Description: Defines the logging level for the application.</li> <li>Variable: <code>LOGGING_LEVEL</code></li> <li>Type: <code>logging</code> (module from Python's standard library)</li> <li>Usage: Set to <code>logging.DEBUG</code> for detailed debugging information. Can be changed to other levels like <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>, etc.</li> </ul>"},{"location":"user_guide/api/config/#database-connection-setting","title":"Database Connection Setting","text":"<ul> <li>Description: Manages the Database URI connection settings.</li> <li>Variable: <code>DB_URI</code></li> <li>Type: <code>string</code></li> <li>Usage: The URI is stored as an environment variable for security reasons. It can be set in a Jupyter notebook, using the os.environ module, or as a system environment variable in bash.</li> </ul>"},{"location":"user_guide/api/config/#database-schema","title":"Database Schema","text":"<ul> <li>Description: Describes the schema for the experiment metadata and plate layout in the database.</li> <li>Variables: <code>DATABASE_SCHEMA</code>, <code>PLATE_LAYOUT_INFO</code></li> <li>Type: <code>dict</code>, <code>list</code></li> <li>Usage: Outlines the structure and column names for the experiment metadata and plate layout tables.</li> </ul>"},{"location":"user_guide/api/config/#image-quality-metadata-schema","title":"Image Quality Metadata Schema","text":"<ul> <li>Description: Defines metadata type for image quality.</li> <li>Variable: <code>IMAGE_QUALITY_METADATA_TYPE</code></li> <li>Type: <code>string</code></li> <li>Usage: Used to specify the metadata type for image quality data, typically retrieved from ImageDB.</li> </ul>"},{"location":"user_guide/api/config/#image-quality-module-data","title":"Image Quality Module Data","text":"<ul> <li>Description: Specifies file prefix for image quality data files.</li> <li>Variable: <code>IMAGE_QUALITY_FILE_PREFIX</code></li> <li>Type: <code>string</code></li> <li>Usage: Indicates the prefix for raw files containing image quality data.</li> </ul>"},{"location":"user_guide/api/config/#cell-morphology-metadata-schema","title":"Cell Morphology Metadata Schema","text":"<ul> <li>Description: Defines metadata type for cell morphology data.</li> <li>Variable: <code>CELL_MORPHOLOGY_METADATA_TYPE</code></li> <li>Type: <code>string</code></li> <li>Usage: Used to specify the metadata type for cell morphology data files.</li> </ul>"},{"location":"user_guide/api/config/#metadata-columns-in-image-quality-and-morphology-file","title":"Metadata Columns in Image Quality and Morphology File","text":"<ul> <li>Description: Lists the metadata columns used in image quality and morphology data files.</li> <li>Variables: <code>METADATA_ACQID_COLUMN</code>, <code>METADATA_BARCODE_COLUMN</code>, <code>METADATA_WELL_COLUMN</code>, <code>METADATA_SITE_COLUMN</code>, <code>METADATA_IMAGE_NUMBER_COLUMN</code></li> <li>Type: <code>string</code></li> <li>Usage: Identifies specific metadata columns in the data files for referencing acquisition, barcode, well, site, and image number.</li> </ul>"},{"location":"user_guide/api/config/#object-morphology-data-file","title":"Object Morphology Data File","text":"<ul> <li>Description: Details the configuration for object morphology data files.</li> <li>Variables: <code>OBJECT_FILE_NAMES</code>, <code>OBJECT_ID_COLUMN</code>, <code>OBJECT_PARENT_CELL_COLUMN</code>, <code>CELL_CYTOPLASM_COUNT_COLUMN</code>, <code>CELL_NUCLEI_COUNT_COLUMN</code></li> <li>Type: <code>list</code>, <code>string</code></li> <li>Usage: Specifies file names and column names for data related to object morphology, such as cell nuclei and cytoplasm.</li> </ul>"},{"location":"user_guide/api/config/#image-and-cell-id-construction","title":"Image and Cell ID Construction","text":"<ul> <li>Description: Constructs unique identifiers for images and cells.</li> <li>Variables: <code>IMAGE_ID_COLUMN_NAME</code>, <code>CELL_ID_COLUMN_NAME</code>, <code>CONSTRUCTING_IMAGE_ID</code>, <code>CONSTRUCTING_CELL_ID</code></li> <li>Type: <code>string</code>, <code>polars</code> expression</li> <li>Usage: Combines various metadata fields to create unique identifiers for images and cells.</li> </ul>"},{"location":"user_guide/api/config/#aggregation-method-for-each-level","title":"Aggregation Method for Each Level","text":"<ul> <li>Description: Defines aggregation methods for different levels (cell, site, well, etc.).</li> <li>Variable: <code>AGGREGATION_METHOD_DICT</code></li> <li>Type: <code>dict</code></li> <li>Usage: Specifies the aggregation method (mean, median, sum, etc.) for different levels of data analysis.</li> </ul>"},{"location":"user_guide/api/config/#grouping-column-map","title":"Grouping Column Map","text":"<ul> <li>Description: Maps aggregation levels to their respective grouping columns.</li> <li>Variable: <code>GROUPING_COLUMN_MAP</code></li> <li>Type: <code>dict</code></li> <li>Usage: Details the columns used for grouping data at different levels (cell, site, well, etc.).</li> </ul>"},{"location":"user_guide/api/config/#qc-modules-setting","title":"QC Modules Setting","text":"<ul> <li>Description: Specifies default quality control modules to consider.</li> <li>Variable: <code>DEFAULT_QC_MODULES</code></li> <li>Type: <code>set</code></li> <li>Usage: Lists the default modules used for quality control assessment.</li> </ul>"},{"location":"user_guide/api/config/#plot-discrete-color","title":"Plot Discrete Color","text":"<ul> <li>Description: Provides color settings for plots.</li> <li>Variable: <code>COLORS</code></li> <li>Type: <code>plotly.express.colors</code></li> <li>Usage: Defines a set of colors from Plotly's qualitative Set1 for use in data visualizations.</li> </ul> <p>Notes</p> <ul> <li>Security: Care should be taken with <code>DB_URI</code> to ensure that database connections are secure.</li> <li>Flexibility: The configuration allows for customization of data schemas, aggregation methods, and quality control modules, making it adaptable to various research needs.</li> <li>Dependencies: The configuration relies on external libraries like <code>logging</code>, <code>os</code>, <code>polars</code>, and <code>plotly</code>.</li> </ul>"},{"location":"user_guide/api/data_processing/","title":"Data processing","text":""},{"location":"user_guide/api/data_processing/#pharmbiodata_processingfeature_aggregation","title":"<code>pharmbio.data_processing.feature_aggregation</code>","text":"<p>This module contains functions designed to perform data aggregation tasks efficiently, utilizing either CPU or GPU resources. Here's a breakdown of its key purposes:</p>"},{"location":"user_guide/api/data_processing/#aggregate_data_cpu","title":"<code>aggregate_data_cpu()</code>","text":"<p>Aggregates morphology data using specified columns and an aggregation function on CPU.</p>"},{"location":"user_guide/api/data_processing/#syntax-source","title":"Syntax [source]","text":"<pre><code>def aggregate_data_cpu(\n    df: Union[pl.DataFrame, pd.DataFrame],\n    columns_to_aggregate: List[str],\n    groupby_columns: List[str],\n    aggregation_function: str = \"mean\",\n) -&gt; pl.DataFrame:\n</code></pre>"},{"location":"user_guide/api/data_processing/#parameters","title":"Parameters","text":"<ul> <li><code>df</code> (Union[pl.DataFrame, pd.DataFrame]): The input DataFrame to be aggregated. Can be either a Polars or Pandas DataFrame.</li> <li><code>columns_to_aggregate</code> (List[str]): List of column names to be aggregated.</li> <li><code>groupby_columns</code> (List[str]): List of column names to group by.</li> <li><code>aggregation_function</code> (str, optional): The aggregation function to be applied. Defaults to \"mean\". Other possible values include \"median\", \"sum\", \"min\", \"max\".</li> </ul>"},{"location":"user_guide/api/data_processing/#returns","title":"Returns","text":"<ul> <li><code>pl.DataFrame</code>: The aggregated Polars DataFrame.</li> </ul>"},{"location":"user_guide/api/data_processing/#examples","title":"Examples","text":"<pre><code>df = pl.DataFrame({\n    'A': [1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4],\n    'B': [1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2],\n    'C': [9, 10, 11, 12, 9, 10, 11, 12, 12, 11, 12],\n    'D': [1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4]})\n\naggregate_data_cpu(df, columns_to_aggregate=['B', 'C'], groupby_columns=['A'], aggregation_function='mean')\n</code></pre>"},{"location":"user_guide/api/data_processing/#aggregate_data_gpu","title":"<code>aggregate_data_gpu()</code>","text":"<p>Aggregates data using specified columns and an aggregation function with GPU acceleration.</p>"},{"location":"user_guide/api/data_processing/#syntax-source_1","title":"Syntax [source]","text":"<pre><code>def aggregate_data_gpu(\n    df: Union[pl.DataFrame, pd.DataFrame],\n    columns_to_aggregate: List[str],\n    groupby_columns: List[str],\n    aggregation_function: str = \"mean\",\n) -&gt; pl.DataFrame:\n</code></pre>"},{"location":"user_guide/api/data_processing/#parameters_1","title":"Parameters","text":"<ul> <li>Same as <code>aggregate_data_cpu</code>.</li> </ul>"},{"location":"user_guide/api/data_processing/#returns_1","title":"Returns","text":"<ul> <li><code>pl.DataFrame</code>: The aggregated DataFrame.</li> </ul>"},{"location":"user_guide/api/data_processing/#raises","title":"Raises","text":"<ul> <li><code>ImportError</code>: Raised when the CuPy package is not available.</li> <li><code>RuntimeError</code>: Raised when an unexpected error occurs during the aggregation process.</li> </ul>"},{"location":"user_guide/api/data_processing/#examples_1","title":"Examples","text":"<pre><code>df = pd.DataFrame({\n\n\n    'A': [1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4],\n    'B': [1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2],\n    'C': [9, 10, 11, 12, 9, 10, 11, 12, 12, 11, 12],\n    'D': [1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4]})\n\naggregate_data_gpu(df, columns_to_aggregate=['B', 'C'], groupby_columns=['A'], aggregation_function='mean')\n</code></pre> <p>Info</p> <ul> <li>The GPU-accelerated version (<code>aggregate_data_gpu</code>) requires the CuPy package for execution. Ensure that it is installed and configured correctly in your environment for optimal performance.</li> <li>GPU acceleration is beneficial for large datasets, where it can significantly speed up the aggregation process compared to CPU-based aggregation.</li> </ul>"},{"location":"user_guide/api/data_processing/#pharmbiodata_processingquality_control","title":"<code>pharmbio.data_processing.quality_control</code>","text":"<p>This module includes functions <code>get_qc_module</code>, <code>get_qc_data_dict</code>, <code>get_channels</code>, and <code>flag_outlier_images</code> to performe all neccessary part of the quality control on the data:</p>"},{"location":"user_guide/api/data_processing/#get_qc_module","title":"<code>get_qc_module()</code>","text":"<p>Returns a sorted list of image quality module names extracted from the given QC data.</p>"},{"location":"user_guide/api/data_processing/#syntax-source_2","title":"Syntax [source]","text":"<pre><code>def get_qc_module(qc_data: Union[pl.DataFrame, pd.DataFrame]) -&gt; List[str]:\n</code></pre>"},{"location":"user_guide/api/data_processing/#parameters_2","title":"Parameters","text":"<ul> <li><code>qc_data</code> (Union[pl.DataFrame, pd.DataFrame]): QC data containing columns related to image quality.</li> </ul>"},{"location":"user_guide/api/data_processing/#returns_2","title":"Returns","text":"<ul> <li><code>List[str]</code>: A sorted list of QC module names.</li> </ul>"},{"location":"user_guide/api/data_processing/#example","title":"Example","text":"<pre><code>qc_data = get_image_quality_ref('AROS-Reproducibility-MoA-Full')\nqc_modules = get_qc_module(qc_data)\nprint(qc_modules)\n\n# output: ['Correlation', 'FocusScore', 'LocalFocusScore', ... ]\n</code></pre>"},{"location":"user_guide/api/data_processing/#get_qc_data_dict","title":"<code>get_qc_data_dict()</code>","text":"<p>Returns a dictionary of image quality module data frames filtered by the specified modules.</p>"},{"location":"user_guide/api/data_processing/#syntax-source_3","title":"Syntax [source]","text":"<pre><code>def get_qc_data_dict(\n    qc_data: Union[pl.DataFrame, pd.DataFrame],\n    module_to_keep: Set[str] = None,\n    module_to_drop: Set[str] = None\n) -&gt; Dict[str, pl.DataFrame]:\n</code></pre>"},{"location":"user_guide/api/data_processing/#parameters_3","title":"Parameters","text":"<ul> <li><code>qc_data</code> (Union[pl.DataFrame, pd.DataFrame]): QC data containing columns related to image quality.</li> <li><code>module_to_keep</code> (Set[str], optional): Set of QC modules to keep.</li> <li><code>module_to_drop</code> (Set[str], optional): Set of QC modules to drop.</li> </ul>"},{"location":"user_guide/api/data_processing/#returns_3","title":"Returns","text":"<ul> <li><code>Dict[str, pl.DataFrame]</code>: Dictionary of QC data frames filtered by specified modules.</li> </ul>"},{"location":"user_guide/api/data_processing/#example_1","title":"Example","text":"<pre><code>qc_data_dict = get_qc_data_dict(qc_data, module_to_keep={'FocusScore'})\nprint(qc_data_dict)\n</code></pre>"},{"location":"user_guide/api/data_processing/#get_channels","title":"<code>get_channels()</code>","text":"<p>Returns a dictionary of channels</p> <p>and sub-channels for each QC module in the given QC data.</p>"},{"location":"user_guide/api/data_processing/#syntax-source_4","title":"Syntax [source]","text":"<pre><code>def get_channels(\n    qc_data: Union[pl.DataFrame, pd.DataFrame],\n    qc_module_list: List[str] = None,\n    out_put: str = \"dict\"\n) -&gt; Dict[str, Dict[str, List[str]]]:\n</code></pre>"},{"location":"user_guide/api/data_processing/#parameters_4","title":"Parameters","text":"<ul> <li><code>qc_data</code> (Union[pl.DataFrame, pd.DataFrame]): The QC data containing columns related to image quality.</li> <li><code>qc_module_list</code> (List[str], optional): The list of QC modules to consider.</li> <li><code>out_put</code> (str, optional): The output format (\"dict\" or \"print\").</li> </ul>"},{"location":"user_guide/api/data_processing/#returns_4","title":"Returns","text":"<ul> <li><code>Dict[str, Dict[str, List[str]]]</code>: A dictionary of channels and sub-channels for each QC module.</li> </ul>"},{"location":"user_guide/api/data_processing/#example_2","title":"Example","text":"<pre><code>qc_data = pd.DataFrame({\n    'ImageQuality_FocusScore_CONC': [0.5, 0.6, 0.7],\n    'ImageQuality_FocusScore_HOECHST': [0.8, 0.9, 1.0],\n    'ImageQuality_Intensity_CONC': [1, 2, 3],\n    'OtherColumn': ...\n})\nchannels = get_channels(qc_data)\nprint(channels)\n\n# Output:{'FocusScore': {'channels': ['CONC', 'HOECHST'], 'sub_channels': []},\n#         'Intensity': {'channels': ['CONC'], 'sub_channels': []}\n</code></pre>"},{"location":"user_guide/api/data_processing/#flag_outlier_images","title":"<code>flag_outlier_images()</code>","text":"<p>Flags outlier images based on specified quality control (QC) data.</p>"},{"location":"user_guide/api/data_processing/#syntax-source_5","title":"Syntax [source]","text":"<pre><code>def flag_outlier_images(\n    qc_data: Union[pl.DataFrame, pd.DataFrame],\n    module_to_keep: Set[str] = None,\n    module_to_drop: Set[str] = None,\n    method: Literal[\"SD\", \"IQR\"] = \"SD\",\n    IQR_normalization: bool = True,\n    normalization: Literal[\"zscore\", \"minmax\"] = \"zscore\",\n    sd_step_dict: Dict[str, Tuple[float, float]] = None,\n    default_sd_step: Tuple[float, float] = (-4.5, 4.5),\n    quantile_limit: float = 0.25,\n    multiplier: float = 1.5\n) -&gt; pl.DataFrame:\n</code></pre>"},{"location":"user_guide/api/data_processing/#parameters_5","title":"Parameters","text":"<ul> <li><code>qc_data</code> (Union[pl.DataFrame, pd.DataFrame]): QC data containing columns related to image quality.</li> <li><code>module_to_keep</code> (Set[str], optional): Set of QC modules to keep.</li> <li><code>module_to_drop</code> (Set[str], optional): Set of QC modules to drop.</li> <li><code>method</code> (Literal[\"SD\", \"IQR\"], optional): Method used for outlier detection (\"SD\" for standard deviation or \"IQR\" for interquartile range). Defaults to \"SD\".</li> <li><code>IQR_normalization</code> (bool, optional): Whether to perform IQR normalization. Applicable when method is \"IQR\". Defaults to True.</li> <li><code>normalization</code> (Literal[\"zscore\", \"minmax\"], optional): Normalization method (\"zscore\" or \"minmax\"). Defaults to \"zscore\".</li> <li><code>sd_step_dict</code> (Dict[str, Tuple[float, float]], optional): Dictionary specifying SD steps for each module.</li> <li><code>default_sd_step</code> (Tuple[float, float], optional): Default SD steps for outlier detection set to (-4.5, 4.5).</li> <li><code>quantile_limit</code> (float, optional): Quantile limit for IQR method. Defaults to 0.25.</li> <li><code>multiplier</code> (float, optional): Multiplier for IQR method. Defaults to 1.5.</li> </ul>"},{"location":"user_guide/api/data_processing/#returns_5","title":"Returns","text":"<ul> <li><code>pl.DataFrame</code>: QC data with flagged outlier images based on specified criteria.</li> </ul>"},{"location":"user_guide/api/data_processing/#raises_1","title":"Raises","text":"<ul> <li><code>ValueError</code>: If the quantile limit or multiplier is not within the specified range.</li> </ul>"},{"location":"user_guide/api/data_processing/#example_3","title":"Example","text":"<pre><code>qc_data = get_image_quality_data(name='AROS-Reproducibility-MoA-Full')\nflagged_qc_data = flag_outlier_images(qc_data, module_to_keep={'FocusScore'})\nprint(flagged_qc_data)\n</code></pre>"},{"location":"user_guide/api/database/","title":"Database","text":""},{"location":"user_guide/api/database/#pharmbiodatabasequeries","title":"<code>pharmbio.database.queries</code>","text":"<p>The primary purpose of this module is to create and execute SQL queries for retrieving specific types of data from a database.</p>"},{"location":"user_guide/api/database/#experiment_name_sql_query","title":"<code>experiment_name_sql_query()</code>","text":"<p>Executes a SQL query to retrieve experiment names from a specified table in the database.</p>"},{"location":"user_guide/api/database/#syntax-source","title":"Syntax [source]","text":"<pre><code>def experiment_name_sql_query(experiment_name: str, table_name_on_db: str) -&gt; str:\n</code></pre>"},{"location":"user_guide/api/database/#parameters","title":"Parameters","text":"<ul> <li><code>experiment_name</code> (str): Name of the experiment column to select.</li> <li><code>table_name_on_db</code> (str): Name of the table to query in the database.</li> </ul>"},{"location":"user_guide/api/database/#returns","title":"Returns","text":"<ul> <li><code>str</code>: SQL query string to retrieve experiment names.</li> </ul>"},{"location":"user_guide/api/database/#experiment_metadata_sql_query","title":"<code>experiment_metadata_sql_query()</code>","text":"<p>Executes a SQL query to retrieve metadata for a specific experiment from the database.</p>"},{"location":"user_guide/api/database/#syntax-source_1","title":"Syntax [source]","text":"<pre><code>def experiment_metadata_sql_query(name: str, db_schema: dict, experiment_type: str) -&gt; str:\n</code></pre>"},{"location":"user_guide/api/database/#parameters_1","title":"Parameters","text":"<ul> <li><code>name</code> (str): Name of the experiment to search for.</li> <li><code>db_schema</code> (dict): A dictionary containing the names of the database schema tables and columns. Keys should include  <code>'EXPERIMENT_METADATA_TABLE_NAME_ON_DB'</code>, <code>'EXPERIMENT_NAME_COLUMN'</code>, <code>'EXPERIMENT_ANALYSIS_DATE_COLUMN'</code>, <code>'EXPERIMENT_PLATE_BARCODE_COLUMN'</code>, <code>'EXPERIMENT_PLATE_ACQID_COLUMN'</code>, and <code>'EXPERIMENT_ANALYSIS_ID_COLUMN'</code>, each mapped to their corresponding names in the database.</li> <li>experiment_type (str): The type of experiment to filter the query by. This allows the query to return metadata for a specific type of experiment. Valid values are \"cp-qc\" for quality control and \"cp-features\" for cell features.</li> </ul>"},{"location":"user_guide/api/database/#returns_1","title":"Returns","text":"<p>Returns</p> <ul> <li><code>str</code>: SQL query string to retrieve experiment names.</li> </ul>"},{"location":"user_guide/api/database/#example","title":"Example","text":"<pre><code>name = 'my_experiment'\ndb_schema = {\n    'EXPERIMENT_METADATA_TABLE_NAME_ON_DB': 'experiment_table',\n    'EXPERIMENT_NAME_COLUMN': 'name',\n    'EXPERIMENT_ANALYSIS_DATE_COLUMN': 'analysis_date',\n    'EXPERIMENT_PLATE_BARCODE_COLUMN': 'plate_barcode',\n    'EXPERIMENT_PLATE_ACQID_COLUMN': 'plate_acqid',\n    'EXPERIMENT_ANALYSIS_ID_COLUMN': 'analysis_id'\n}\nexperiment_type = 'cp-features'\n\nquery = experiment_metadata_sql_query(name, db_schema, experiment_type)\nprint(query)\n</code></pre>"},{"location":"user_guide/api/database/#plate_layout_sql_query","title":"<code>plate_layout_sql_query</code>()","text":"<p>Executes a SQL query to retrieve plate layout information from the database based on the given plate barcode.</p>"},{"location":"user_guide/api/database/#syntax-source_2","title":"Syntax [source]","text":"<pre><code>def plate_layout_sql_query(db_schema: dict, plate_barcode: str) -&gt; str:\n</code></pre>"},{"location":"user_guide/api/database/#parameters_2","title":"Parameters","text":"<ul> <li><code>db_schema</code> (dict): A dictionary containing the names of the database schema tables. This should include keys like <code>'PLATE_LAYOUT_TABLE_NAME_ON_DB'</code>, <code>'PLATE_LAYOUT_BARCODE_COLUMN'</code>, and <code>'PLATE_COMPOUND_NAME_COLUMN'</code> with their corresponding table and column names in the database.</li> <li><code>plate_barcode</code> (str): The barcode identifier of the plate for which layout information is being queried.</li> </ul>"},{"location":"user_guide/api/database/#returns_2","title":"Returns","text":"<ul> <li><code>str</code>: A string representing the SQL query. This query is structured to select plate layout information from the specified database schema based on the provided plate barcode.</li> </ul>"},{"location":"user_guide/api/database/#example_1","title":"Example","text":"<pre><code>db_schema = {\n    'PLATE_LAYOUT_TABLE_NAME_ON_DB': 'plate_v1',\n    'PLATE_LAYOUT_BARCODE_COLUMN': 'barcode',\n    'PLATE_COMPOUND_NAME_COLUMN': 'batch_id'\n}\nplate_barcode = 'ABC123'\n\nquery = plate_layout_sql_query(db_schema, plate_barcode)\n</code></pre>"},{"location":"user_guide/api/dataset/","title":"Dataset","text":""},{"location":"user_guide/api/dataset/#pharmbiodatasetexperiment","title":"<code>pharmbio.dataset.experiment</code>","text":"<p>This module contains functions related to handling and querying experiment-related data in the <code>pharmbio</code> package.</p>"},{"location":"user_guide/api/dataset/#get_projects_list","title":"<code>get_projects_list()</code>","text":"<p>Retrieves a list of project names from the database, with an optional filter to return only those projects that contain a specified substring in their names.</p>"},{"location":"user_guide/api/dataset/#syntax-source","title":"Syntax [source]","text":"<pre><code>def get_projects_list(lookup: str = None) -&gt; list:\n</code></pre>"},{"location":"user_guide/api/dataset/#parameters","title":"Parameters","text":"<ul> <li><code>lookup</code> (str, optional): A string to filter the project list. If provided, the function returns only those projects that contain the <code>lookup</code> string in their names. The search is case-insensitive and the <code>lookup</code> string can match any part of a project name. Defaults to <code>None</code>, which returns all project names.</li> </ul>"},{"location":"user_guide/api/dataset/#returns","title":"Returns","text":"<ul> <li><code>list</code>: A list of project names. If <code>lookup</code> is provided, it returns a filtered list of names that contain the <code>lookup</code> string. If <code>lookup</code> is <code>None</code>, it returns all project names.</li> </ul>"},{"location":"user_guide/api/dataset/#examples","title":"Examples","text":"<ol> <li> <p>Retrieving All Projects:    To get a complete list of all projects:    <pre><code>project_list = get_projects_list()\nprint(project_list)\n# Output: ['Project A', 'Project B', 'Project C', ...]\n</code></pre></p> </li> <li> <p>Retrieving Filtered Projects:    To get a list of projects that include a specific substring (e.g., 'aros'):    <pre><code>filtered_list = get_projects_list(lookup='aros')\nprint(filtered_list)\n# Output might include: ['AROS-CP', 'AROS-Reproducibility-MoA-Full', ...]\n</code></pre></p> </li> </ol> <p>Info</p> <ul> <li>The function performs a case-insensitive search when the <code>lookup</code> parameter is used.</li> <li>The search functionality can identify partial matches in project names, making it versatile for a variety of search requirements.</li> <li>It is essential to ensure that your workspace is connected to the correct database server as outlined in the Configuration section of the documentation, as this function depends on database access.</li> </ul>"},{"location":"user_guide/api/dataset/#experiment","title":"<code>Experiment</code>","text":"<p>This class encapsulates an entire experiment, providing functionalities to load, process, and analyze various aspects of experimental data.</p>"},{"location":"user_guide/api/dataset/#syntax-source_1","title":"Syntax [source]","text":"<pre><code>class Experiment:\n    def __init__(self, json_file: str):\n</code></pre>"},{"location":"user_guide/api/dataset/#parameters_1","title":"Parameters","text":"<ul> <li><code>json_file</code> (str): The path to a JSON file containing the experiment's data. This file should contain relevant information needed to initialize and populate the experiment's attributes.</li> </ul>"},{"location":"user_guide/api/dataset/#attributes","title":"Attributes","text":"<ul> <li><code>image_quality_data</code>: Stores the image quality data related to the experiment.</li> <li><code>flagged_image_quality_data</code>: Contains image quality data that has been flagged for quality issues.</li> <li><code>cell_morphology_data</code>: Holds cell morphology data from the experiment.</li> <li><code>compound_batch_ids</code>: A list of IDs associated with different compound batches used in the experiment.</li> <li><code>compound_outlier_info</code>: Information about outliers identified in the experiment's flagged image quality data.</li> <li><code>outlier_dataframe</code>: A DataFrame that includes detailed outlier information for the experiment's flagged image quality data.</li> </ul>"},{"location":"user_guide/api/dataset/#methods","title":"Methods","text":"<ul> <li><code>get_image_quality_reference_data()</code>: Returns reference data for image quality analysis.</li> <li><code>get_image_quality_data()</code>: Retrieves and processes image quality data based on the provided reference data.</li> <li><code>get_cell_morphology_reference_data()</code>: Returns reference data for cell morphology analysis.</li> <li><code>get_cell_morphology_data()</code>: Retrieves and processes cell morphology data based on the provided reference data.</li> <li><code>get_image_quality_modules()</code>: Returns the image quality modules used in the experiment.</li> <li><code>get_image_quality_data_dict()</code>: Provides a dictionary representation of the image quality data.</li> <li><code>flag_outlier_images()</code>: Identifies and flags outlier images based on specified criteria.</li> <li><code>plate_heatmap(...)</code>: Generates heatmaps for the given plates in the experiment.</li> <li><code>well_outlier_heatmap()</code>: Creates a heatmap for well outliers in the experiment.</li> <li><code>quality_module_lineplot(...)</code>: Plots a line graph for the selected quality modules.</li> <li><code>print_setting()</code>: Prints the current settings and configuration of the experiment in a readable format.</li> </ul>"},{"location":"user_guide/api/dataset/#examples_1","title":"Examples","text":"<p>To initialize an <code>Experiment</code> instance with a specified JSON file: <pre><code>experiment = Experiment('path/to/experiment_data.json')\n</code></pre></p> <p>To retrieve and print the image quality data: <pre><code>image_quality_data = experiment.get_image_quality_data()\n</code></pre></p> <p>To generate a heatmap for a specific plate: <pre><code>experiment.plate_heatmap()\n</code></pre></p> <p>Info</p> <ul> <li>The <code>Experiment</code> class is a comprehensive tool for handling complex experimental data, particularly in the fields of cell morphology and compound analysis.</li> <li>It is important to provide a correctly formatted JSON file to ensure proper initialization of the experiment.</li> <li>Some methods of the <code>Experiment</code> class might require additional dependencies to be installed or specific configurations to be set in your working environment.</li> </ul>"},{"location":"user_guide/api/dataset/#pharmbiodatasetcell_morphology","title":"<code>pharmbio.dataset.cell_morphology</code>","text":"<p>This module contains functions related to handling and querying cell morphology data in the <code>pharmbio</code> package.</p>"},{"location":"user_guide/api/dataset/#get_cell_morphology_ref","title":"<code>get_cell_morphology_ref()</code>","text":"<p>Retrieves cell morphology references from a specified database, allowing users to specify a reference name and apply optional filtering conditions to refine the search results. This function is particularly useful for extracting specific cell morphology data based on user-defined criteria.</p>"},{"location":"user_guide/api/dataset/#syntax-source_2","title":"Syntax [source]","text":"<pre><code>def get_cell_morphology_ref(\n    name: str,\n    filter: Optional[Dict[str, str]] = None,\n) -&gt; pl.DataFrame:\n</code></pre>"},{"location":"user_guide/api/dataset/#parameters_2","title":"Parameters","text":"<ul> <li><code>name</code> (str): The name of the cell morphology reference to be retrieved. This is a mandatory parameter.</li> <li><code>filter</code> (dict, optional): A dictionary specifying filter conditions for the query. Each key represents a column name, and its corresponding value is a list of strings to match in that column. The filter uses logical OR for values under the same key and logical AND across different keys. Defaults to <code>None</code>, indicating no filter will be applied.</li> </ul>"},{"location":"user_guide/api/dataset/#returns_1","title":"Returns","text":"<ul> <li><code>pl.DataFrame</code>: A pandas-like DataFrame containing the filtered cell morphology references. The DataFrame's structure depends on the database schema and the applied filter.</li> </ul>"},{"location":"user_guide/api/dataset/#examples_2","title":"Examples","text":"<p>Retrieve a specific cell morphology reference with optional filtering:</p> <pre><code>name = \"example_reference\"\nfilter = {\n    \"column1\": [\"value_1\", \"value2\"],  # Values combined with OR within the same key\n    \"column2\": [\"value3\"]              # Different keys combined with AND\n}\nfiltered_df = get_cell_morphology_ref(name, filter)\ndisplay(filtered_df)\n</code></pre> <p>Info</p> <ul> <li>The function constructs a SQL query using internal configuration parameters such as the database schema and cell morphology metadata type.</li> <li>It executes the query against the database specified in the configuration, retrieving relevant data based on the provided <code>name</code> and <code>filter</code>.</li> <li>When a filter is provided, the function applies the filter conditions iteratively to the DataFrame, allowing for complex query constructions.</li> <li>Ensure that your workspace is properly configured for database connectivity as outlined in the Configuration section of the documentation.</li> </ul>"},{"location":"user_guide/api/dataset/#_get_join_columns","title":"<code>_get_join_columns()</code>","text":"<p>Generates a list of columns to be used for joining tables based on a specified object type in cell morphology datasets. This function is a utility intended for internal use within the <code>cell_morphology</code> module.</p>"},{"location":"user_guide/api/dataset/#syntax-source_3","title":"Syntax [source]","text":"<pre><code>def _get_join_columns(object_type: str) -&gt; list:\n</code></pre>"},{"location":"user_guide/api/dataset/#parameters_3","title":"Parameters","text":"<ul> <li><code>object_type</code> (str): The type of the object. Must be one of <code>'cells'</code>, <code>'cytoplasm'</code>, or <code>'nuclei'</code>. This parameter determines the set of columns relevant for the join operation in cell morphology datasets.</li> </ul>"},{"location":"user_guide/api/dataset/#returns_2","title":"Returns","text":"<ul> <li><code>list</code>: A list of column names to join on. These columns are dynamically determined based on the <code>object_type</code>.</li> </ul>"},{"location":"user_guide/api/dataset/#raises","title":"Raises","text":"<ul> <li><code>ValueError</code>: This error is raised if the <code>object_type</code> is not one of the allowed types ('cells', 'cytoplasm', 'nuclei').</li> </ul>"},{"location":"user_guide/api/dataset/#examples_3","title":"Examples","text":"<p>Usage of this function typically occurs internally within the <code>cell_morphology</code> module. Here is an example scenario of its use:</p> <pre><code># Example of an internal call within the module\nobject_type = 'cells'\njoin_columns = _get_join_columns(object_type)\n</code></pre> <p>Info</p> <ul> <li>The function dynamically determines the allowed object types from from <code>OBJECT_FILE_NAMES</code> object located in in <code>pharmbio.config</code> .</li> <li>It constructs the list of join columns based on the provided <code>object_type</code>, ensuring that the resulting list is specific to the context of the object type.</li> <li>This function is designed for internal use within the module, providing support for complex data operations involving cell morphology datasets.</li> <li>Proper understanding of the database schema and configuration (as outlined in <code>pharmbio.config</code>) is necessary to effectively utilize this function.</li> </ul>"},{"location":"user_guide/api/dataset/#_join_object_dataframes","title":"<code>_join_object_dataframes()</code>","text":"<p>Merges multiple object-related dataframes based on specified columns, facilitating the combination of different cell morphology datasets. This function is designed for internal use within the <code>cell_morphology</code> module.</p>"},{"location":"user_guide/api/dataset/#syntax-source_4","title":"Syntax [source]","text":"<pre><code>def _join_object_dataframes(dfs: Dict[str, pl.DataFrame]) -&gt; pl.DataFrame:\n</code></pre>"},{"location":"user_guide/api/dataset/#parameters_4","title":"Parameters","text":"<ul> <li><code>dfs</code> (Dict[str, pl.DataFrame]): A dictionary containing dataframes keyed by object type (<code>'cells'</code>, <code>'cytoplasm'</code>, <code>'nuclei'</code>). Each key corresponds to an object type and its associated dataframe.</li> </ul>"},{"location":"user_guide/api/dataset/#returns_3","title":"Returns","text":"<ul> <li><code>pl.DataFrame</code>: The resulting dataframe after joining the specified dataframes. This dataframe combines the data from the different object types into a single unified structure.</li> </ul>"},{"location":"user_guide/api/dataset/#examples_4","title":"Examples","text":"<p>Usage of this function typically occurs internally within the <code>cell_morphology</code> module. Here is an example scenario of its use:</p> <pre><code># Example of internal usage within the module\ndataframes = {\n    \"cells\": cells_df,\n    \"nuclei\": nuclei_df,\n    \"cytoplasm\": cytoplasm_df\n}\njoined_df = _join_object_dataframes(dataframes)\n# joined_df is the combined dataframe of cells, nuclei, and cytoplasm data\n</code></pre> <p>Info</p> <ul> <li>The function performs a series of join operations on the dataframes provided in the <code>dfs</code> dictionary.</li> <li>It uses the <code>_get_join_columns</code> function to determine the appropriate columns to join on for each object type.</li> <li>The join operations are executed in a specific order to ensure correct alignment and integration of the data across different cell morphology datasets.</li> <li>This function is crucial for scenarios where data from multiple cell components (cells, nuclei, cytoplasm) need to be combined for comprehensive analysis.</li> <li>As an internal utility function, it plays a key role in facilitating complex data manipulations within the cell morphology module.</li> </ul>"},{"location":"user_guide/api/dataset/#_rename_joined_df_columns","title":"<code>_rename_joined_df_columns()</code>","text":"<p>Renames specific columns in a dataframe, typically used to simplify column names after joining multiple dataframes. This function targets columns that have had additional identifiers appended to them during the join operation, such as '_cells', and removes these parts to restore the original column names. It is intended for internal use within the <code>cell_morphology</code> module.</p>"},{"location":"user_guide/api/dataset/#syntax-source_5","title":"Syntax [source]","text":"<pre><code>def _rename_joined_df_columns(df: pl.DataFrame) -&gt; pl.DataFrame:\n</code></pre>"},{"location":"user_guide/api/dataset/#parameters_5","title":"Parameters","text":"<ul> <li><code>df</code> (pl.DataFrame): The dataframe whose columns are to be renamed. This dataframe is typically the result of a join operation that has appended additional identifiers to certain column names.</li> </ul>"},{"location":"user_guide/api/dataset/#returns_4","title":"Returns","text":"<ul> <li><code>pl.DataFrame</code>: The dataframe with its specific columns renamed. This renaming process removes appended parts like '_cells', returning the dataframe to a more standard column naming convention.</li> </ul>"},{"location":"user_guide/api/dataset/#examples_5","title":"Examples","text":"<p>Usage of this function typically occurs internally within the <code>cell_morphology</code> module. Here is an example scenario of its use:</p> <pre><code># Example of internal usage within the module\njoined_df = _join_object_dataframes(dataframes)\nrenamed_df = _rename_joined_df_columns(joined_df)\n# renamed_df now has simplified column names, removing appended parts from the join operation\n</code></pre> <p>Info</p> <ul> <li>The function focuses on a predefined set of specific columns that are known to undergo renaming during join operations.</li> <li>It creates a mapping (rename_map) to translate from the joined column names back to the original column names.</li> <li>This renaming is crucial for maintaining consistency and clarity in the dataframe, especially after complex join operations.</li> <li>The function is an integral part of data preprocessing within the cell morphology module, ensuring that dataframes are kept in a standardized and easily interpretable format.</li> </ul>"},{"location":"user_guide/api/dataset/#_add_image_cell_id_columns","title":"<code>_add_image_cell_id_columns()</code>","text":"<p>Adds unique Image ID and Cell ID columns to a dataframe. This function is designed to enhance data identification by creating distinct identifiers for each image and cell, based on the existing metadata columns. It is used internally within the <code>cell_morphology</code> module to facilitate easier tracking and analysis of cell morphology data.</p>"},{"location":"user_guide/api/dataset/#syntax-source_6","title":"Syntax [source]","text":"<pre><code>def _add_image_cell_id_columns(df: pl.DataFrame) -&gt; pl.DataFrame:\n</code></pre>"},{"location":"user_guide/api/dataset/#parameters_6","title":"Parameters","text":"<ul> <li><code>df</code> (pl.DataFrame): The original dataframe to which the new ID columns will be added. This dataframe should contain metadata columns that are used to generate the unique identifiers.</li> </ul>"},{"location":"user_guide/api/dataset/#returns_5","title":"Returns","text":"<ul> <li><code>pl.DataFrame</code>: The modified dataframe with two new columns: 'image_id' and 'cell_id'. These columns represent unique identifiers for each image and cell, respectively.</li> </ul>"},{"location":"user_guide/api/dataset/#examples_6","title":"Examples","text":"<p>Usage of this function typically occurs internally within the <code>cell_morphology</code> module. Here is an example scenario of its use:</p> <pre><code># Example of internal usage within the module\noriginal_df = ... # some dataframe with required metadata columns\ndf_with_ids = _add_image_cell_id_columns(original_df)\n# df_with_ids now contains 'image_id' and 'cell_id' columns\n</code></pre> <p>Info</p> <ul> <li>The function constructs the 'image_id' column by concatenating several metadata columns: acquisition ID, barcode, well, and site. This concatenated string uniquely identifies each image.</li> <li>The 'cell_id' column is created by appending the cell object number to the 'image_id', providing a unique identifier for each cell within an image.</li> <li>These additional columns are crucial for tasks that require tracking and analysis at the level of individual images and cells.</li> <li>The function enhances data organization and accessibility, making it easier to reference specific images or cells in complex datasets.</li> </ul>"},{"location":"user_guide/api/dataset/#_drop_unwanted_columns","title":"<code>_drop_unwanted_columns()</code>","text":"<p>Drops specified columns from a dataframe if they exist. This function is used to clean and streamline the dataframe by removing unnecessary or redundant columns, enhancing data clarity and efficiency. It is intended for internal use within the <code>cell_morphology</code> module.</p>"},{"location":"user_guide/api/dataset/#syntax-source_7","title":"Syntax [source]","text":"<pre><code>def _drop_unwanted_columns(df: pl.DataFrame) -&gt; pl.DataFrame:\n</code></pre>"},{"location":"user_guide/api/dataset/#parameters_7","title":"Parameters","text":"<ul> <li><code>df</code> (pl.DataFrame): The dataframe from which the specified columns are to be dropped. This dataframe may contain a variety of columns, some of which are not required for further analysis or operations.</li> </ul>"},{"location":"user_guide/api/dataset/#returns_6","title":"Returns","text":"<ul> <li><code>pl.DataFrame</code>: The modified dataframe with specified unwanted columns removed.</li> </ul>"},{"location":"user_guide/api/dataset/#examples_7","title":"Examples","text":"<p>Usage of this function typically occurs internally within the <code>cell_morphology</code> module. Here is an example scenario of its use:</p> <pre><code># Example of internal usage within the module\noriginal_df = ... # some dataframe with a mix of required and unwanted columns\ncleaned_df = _drop_unwanted_columns(original_df)\n# cleaned_df is now free from specified unwanted columns\n</code></pre> <p>Info</p> <ul> <li>The function targets a predefined list of columns to be dropped, which are identified as unnecessary for the dataset's intended use.</li> <li>These columns might include metadata or derived attributes that are redundant or irrelevant for specific analyses or data processing tasks.</li> <li>By removing these columns, the function helps maintain a focused and efficient dataset, facilitating more effective data handling and analysis.</li> <li>This process of dropping unwanted columns is a common practice in data preprocessing, especially in large datasets with complex structures.</li> </ul>"},{"location":"user_guide/api/dataset/#_cast_metadata_type_columns","title":"<code>_cast_metadata_type_columns()</code>","text":"<p>Ensures data type consistency for specified metadata columns within a dataframe. This function is used to standardize the data types of critical metadata columns, facilitating consistent data processing and analysis. It is intended for internal use within the <code>cell_morphology</code> module.</p>"},{"location":"user_guide/api/dataset/#syntax-source_8","title":"Syntax [source]","text":"<pre><code>def _cast_metadata_type_columns(df: pl.DataFrame) -&gt; pl.DataFrame:\n</code></pre>"},{"location":"user_guide/api/dataset/#parameters_8","title":"Parameters","text":"<ul> <li><code>df</code> (pl.DataFrame): The dataframe whose metadata columns are to be cast to the correct data type. This dataframe typically contains various metadata fields essential for analysis.</li> </ul>"},{"location":"user_guide/api/dataset/#returns_7","title":"Returns","text":"<ul> <li><code>pl.DataFrame</code>: The modified dataframe with specified metadata columns cast to the correct data type.</li> </ul>"},{"location":"user_guide/api/dataset/#examples_8","title":"Examples","text":"<p>Usage of this function typically occurs internally within the <code>cell_morphology</code> module. Here is an example scenario of its use:</p> <pre><code># Example of internal usage within the module\noriginal_df = ... # some dataframe with metadata columns\ndf_with_cast_types = _cast_metadata_type_columns(original_df)\n# df_with_cast_types has metadata columns standardized to the correct data type\n</code></pre> <p>Info</p> <ul> <li>The function focuses on a set of predefined metadata columns crucial for data analysis.</li> <li>These columns are cast to a uniform data type (UTF-8 string) to ensure consistency across the dataset.</li> <li>Standardizing the data types of metadata columns is essential for reliable data processing, particularly when these columns are used in operations like joins, filtering, or aggregation.</li> <li>By casting the metadata columns to a specific type, the function reduces potential issues related to data type mismatches, such as incorrect sorting or failed join operations.</li> <li>This step is a common practice in data preprocessing to ensure that data from various sources or formats aligns correctly for subsequent analysis.</li> </ul>"},{"location":"user_guide/api/dataset/#_get_morphology_feature_cols","title":"<code>_get_morphology_feature_cols()</code>","text":"<p>This function is designed to extract and return the names of columns in a DataFrame that correspond to morphology features.</p>"},{"location":"user_guide/api/dataset/#syntax-source_9","title":"Syntax [source]","text":"<pre><code>def _get_morphology_feature_cols(df: pl.DataFrame) -&gt; List[str]:\n</code></pre>"},{"location":"user_guide/api/dataset/#parameters_9","title":"Parameters","text":"<ul> <li><code>df</code> (<code>polars.DataFrame</code>): The original DataFrame from which morphology feature columns need to be identified.</li> </ul>"},{"location":"user_guide/api/dataset/#returns_8","title":"Returns","text":"<ul> <li><code>List[str]</code>: A list of column names that represent morphology features in the provided DataFrame. The list excludes specific columns like the count of nuclei and cytoplasm in cells.</li> </ul>"},{"location":"user_guide/api/dataset/#examples_9","title":"Examples","text":"<p>To obtain a list of morphology feature column names from a DataFrame: <pre><code>df = # Assume this is a pre-existing DataFrame with cell morphology data\nmorphology_feature_cols = _get_morphology_feature_cols(df)\nprint(\"Morphology Feature Columns:\", morphology_feature_cols)\n</code></pre></p> <p>Info</p> <ul> <li>The <code>_get_morphology_feature_cols</code> function is essential for preprocessing steps in cell morphology analysis, where specific feature columns need to be isolated for further analysis.</li> <li>It automatically filters out non-numeric columns and specific count columns to provide a refined list of relevant features.</li> <li>This function is especially useful in scenarios where datasets contain a mix of morphology-related and non-related data, aiding in efficient data processing and analysis.</li> </ul>"},{"location":"user_guide/api/dataset/#_reorder_dataframe_columns","title":"<code>_reorder_dataframe_columns()</code>","text":"<p>Reorders the columns in a dataframe based on data types and specific columns. This function is designed to organize dataframe columns in a systematic manner, enhancing readability and analysis efficiency. It is intended for internal use within the <code>cell_morphology</code> module.</p>"},{"location":"user_guide/api/dataset/#syntax-source_10","title":"Syntax [source]","text":"<pre><code>def _reorder_dataframe_columns(df: pl.DataFrame) -&gt; pl.DataFrame:\n</code></pre>"},{"location":"user_guide/api/dataset/#parameters_10","title":"Parameters","text":"<ul> <li><code>df</code> (pl.DataFrame): The original dataframe whose columns are to be reordered.</li> </ul>"},{"location":"user_guide/api/dataset/#returns_9","title":"Returns","text":"<ul> <li><code>pl.DataFrame</code>: The dataframe with its columns reordered. The reordering is based on a predefined logic that categorizes columns by their data type and relevance.</li> </ul>"},{"location":"user_guide/api/dataset/#examples_10","title":"Examples","text":"<p>Usage of this function typically occurs internally within the <code>cell_morphology</code> module. Here is an example scenario of its use:</p> <pre><code># Example of internal usage within the module\noriginal_df = ... # some dataframe with various columns\nreordered_df = _reorder_dataframe_columns(original_df)\n# reordered_df has its columns systematically organized\n</code></pre> <p>Info</p> <ul> <li>The function first identifies morphology feature columns using <code>_get_morphology_feature_cols</code>.</li> <li>It then segregates non-numeric columns and sorts them alphabetically.</li> <li>The new column order starts with sorted non-numeric columns, followed by specific count columns (like <code>CELL_NUCLEI_COUNT_COLUMN</code> and <code>CELL_CYTOPLASM_COUNT_COLUMN</code> which are located in config settings), and finally includes the morphology feature columns.</li> <li>This systematic reordering of columns is crucial for maintaining a consistent structure across different dataframes within the module, facilitating easier data manipulation and analysis.</li> <li>The reorganization enhances the clarity of the dataframe, making it more intuitive to work with, especially when dealing with large and complex datasets.</li> <li>By focusing on data types and specific columns, this function ensures that the most critical and relevant data is easily accessible and comprehensible.</li> </ul>"},{"location":"user_guide/api/dataset/#_merge_with_plate_info","title":"<code>_merge_with_plate_info()</code>","text":"<p>Merges a given object dataframe with plate information, enhancing the dataset with additional details relevant to the experimental setup. This function is designed to integrate cellular morphology features with plate layout data, crucial for analysis in cell morphology studies. It is intended for internal use within the <code>cell_morphology</code> module.</p>"},{"location":"user_guide/api/dataset/#syntax-source_11","title":"Syntax [source]","text":"<pre><code>def _merge_with_plate_info(df: pl.DataFrame) -&gt; pl.DataFrame:\n</code></pre>"},{"location":"user_guide/api/dataset/#parameters_11","title":"Parameters","text":"<ul> <li><code>df</code> (pl.DataFrame): The original object dataframe containing cellular morphology features.</li> <li><code>plate_layout_sql_query</code> (callable): A function that returns an SQL query for fetching plate layout information. This parameter is typically configured within the function.</li> </ul>"},{"location":"user_guide/api/dataset/#returns_10","title":"Returns","text":"<ul> <li><code>pl.DataFrame</code>: The dataframe resulting from merging the original dataframe with plate layout information.</li> </ul>"},{"location":"user_guide/api/dataset/#examples_11","title":"Examples","text":"<p>Usage of this function typically occurs internally within the <code>cell_morphology</code> module. Here is an example scenario of its use:</p> <pre><code># Example of internal usage within the module\nobject_df = ... # some dataframe with cellular morphology features\nmerged_df = _merge_with_plate_info(object_df)\n# merged_df now contains both cellular morphology features and plate layout information\n</code></pre> <p>Info</p> <ul> <li>The function starts by extracting unique barcodes from the dataframe to identify the relevant plates.</li> <li>It then fetches plate layout data from the database using a provided SQL query, which is tailored to include only the plates of interest based on their barcodes.</li> <li>The object dataframe and plate layout dataframe are merged on barcode and well information, integrating detailed plate data with the cellular features.</li> <li>This merge process is crucial for experiments where understanding the context of each plate and well is vital for accurate analysis and interpretation.</li> <li>The function ensures that the merged dataframe is free of null values in crucial columns, such as the compound name column, to maintain data integrity and relevance.</li> </ul>"},{"location":"user_guide/api/dataset/#get_outlier_df","title":"<code>get_outlier_df()</code>","text":"<p>This function retrieves a DataFrame containing detailed outlier information from flagged quality control data, particularly useful in cell morphology analysis.</p>"},{"location":"user_guide/api/dataset/#syntax-source_12","title":"Syntax [source]","text":"<pre><code>def get_outlier_df(flagged_qc_df: pl.DataFrame, with_compound_info: bool = False) -&gt; pl.DataFrame:\n</code></pre>"},{"location":"user_guide/api/dataset/#parameters_12","title":"Parameters","text":"<ul> <li><code>flagged_qc_df</code> (<code>polars.DataFrame</code>): A DataFrame containing flagged quality control data. This data is used to identify and analyze outliers in the dataset.</li> <li><code>with_compound_info</code> (<code>bool</code>, optional): A flag to include compound-related information in the returned DataFrame. If set to <code>True</code>, additional compound-related columns such as batch ID, SMILES notation, InChI, and InChIKey are included. Defaults to <code>False</code>.</li> </ul>"},{"location":"user_guide/api/dataset/#returns_11","title":"Returns","text":"<ul> <li><code>polars.DataFrame</code>: A DataFrame containing detailed outlier information. This DataFrame includes columns for acquisition ID, barcode, well, and the number of outliers. It also features a range of integers from 1 to 10 and, optionally, compound-related information if <code>with_compound_info</code> is set to <code>True</code>.</li> </ul>"},{"location":"user_guide/api/dataset/#examples_12","title":"Examples","text":"<p>To obtain a DataFrame with outlier information from a flagged quality control DataFrame: <pre><code>flagged_qc_df = # Assume this is a pre-existing DataFrame with flagged QC data\noutlier_df = get_outlier_df(flagged_qc_df)\nprint(outlier_df)\n</code></pre></p> <p>To include compound information in the outlier DataFrame: <pre><code>outlier_df_with_compound = get_outlier_df(flagged_qc_df, with_compound_info=True)\nprint(outlier_df_with_compound)\n</code></pre></p> <p>Info</p> <ul> <li>The <code>get_outlier_df</code> function is crucial for detailed analysis of outliers in cell morphology datasets, allowing researchers to pinpoint specific areas of concern.</li> <li>The inclusion of compound information can be particularly useful for studies involving chemical screenings or compound-effect analysis.</li> <li>The function relies on the <code>polars</code> library for DataFrame operations, ensuring efficient and fast data manipulation.</li> </ul>"},{"location":"user_guide/api/dataset/#_outlier_series_to_delete","title":"<code>_outlier_series_to_delete()</code>","text":"<p>This function is designed to identify and flag outliers in a Polars DataFrame related to cell morphology data. It determines which compounds and image IDs of sites should be considered for deletion based on specified thresholds.</p>"},{"location":"user_guide/api/dataset/#syntax-source_13","title":"Syntax [source]","text":"<pre><code>def _outlier_series_to_delete(\n    flagged_qc_df: pl.DataFrame, \n    site_threshold: int = 6, \n    compound_threshold: float = 0.7\n) -&gt; (pl.Series, pl.Series, pl.DataFrame):\n</code></pre>"},{"location":"user_guide/api/dataset/#parameters_13","title":"Parameters","text":"<ul> <li><code>flagged_qc_df</code> (<code>polars.DataFrame</code>): A DataFrame containing quality control data with an 'outlier_flag' column. This data is used for identifying outliers.</li> <li><code>site_threshold</code> (<code>int</code>, optional): The threshold for the number of sites in a well above which all sites are considered outliers. The valid range is 1-9. Defaults to 6.</li> <li><code>compound_threshold</code> (<code>float</code>, optional): The threshold for the percentage of data loss at which a compound is considered for deletion. The valid range is 0-1. Defaults to 0.7.</li> </ul>"},{"location":"user_guide/api/dataset/#returns_12","title":"Returns","text":"<ul> <li>A tuple containing two <code>polars.Series</code> and a <code>polars.DataFrame</code>:<ul> <li>The first series contains the identifiers of the compounds to be deleted.</li> <li>The second series includes image IDs of sites to be deleted.</li> <li>The returned DataFrame is used internally for the calculation of these series.</li> </ul> </li> </ul>"},{"location":"user_guide/api/dataset/#examples_13","title":"Examples","text":"<p>To identify compounds and image IDs of sites to delete based on outlier analysis: <pre><code>flagged_qc_df = # Assume this is a pre-existing DataFrame with flagged QC data\ncompounds_to_delete, images_to_delete = _outlier_series_to_delete(flagged_qc_df)\nprint(\"Compounds to delete:\", compounds_to_delete)\nprint(\"Image IDs to delete:\", images_to_delete)\n</code></pre></p> <p>Info</p> <ul> <li>The <code>_outlier_series_to_delete</code> function plays a crucial role in maintaining the integrity of cell morphology datasets by removing unreliable data points.</li> <li>It's important to set appropriate thresholds for both site and compound deletion to ensure accurate data analysis.</li> <li>This function is typically used in more advanced stages of data processing where precise outlier removal can significantly impact the quality of the analysis.</li> </ul>"},{"location":"user_guide/api/dataset/#get_comp_outlier_info","title":"<code>get_comp_outlier_info()</code>","text":"<p>This function computes outlier information for a given DataFrame that contains flagged data. It is particularly useful in the analysis of cell morphology data where identifying and quantifying outliers is crucial.</p>"},{"location":"user_guide/api/dataset/#syntax-source_14","title":"Syntax [source]","text":"<pre><code>def get_comp_outlier_info(flagged_df: pl.DataFrame) -&gt; pl.DataFrame:\n</code></pre>"},{"location":"user_guide/api/dataset/#parameters_14","title":"Parameters","text":"<ul> <li><code>flagged_df</code> (<code>polars.DataFrame</code>): A DataFrame containing flagged data. The data should include columns for batch identification and outlier flags.</li> </ul>"},{"location":"user_guide/api/dataset/#returns_13","title":"Returns","text":"<ul> <li>A <code>polars.DataFrame</code>: This DataFrame includes the following columns:<ul> <li><code>batch_id</code>: Identifier for each batch.</li> <li><code>outlier_img_num</code>: The number of outlier images per compound.</li> <li><code>total_img_num</code>: The total number of images per compound.</li> <li><code>lost_data_percentage</code>: The percentage of data considered as lost due to outliers.</li> </ul> </li> </ul> <p>The returned DataFrame is sorted in descending order based on the number of outlier images.</p>"},{"location":"user_guide/api/dataset/#examples_14","title":"Examples","text":"<p>To calculate the outlier information for a given DataFrame:</p> <pre><code>flagged_df = # Assume this is a pre-existing DataFrame with flagged data\noutlier_info_df = get_comp_outlier_info(flagged_df)\n</code></pre> <p>Info</p> <ul> <li>The <code>get_comp_outlier_info</code> function is essential for understanding the distribution and impact of outliers in your data.</li> <li>It helps in the decision-making process regarding data cleaning and preprocessing, especially in large datasets with numerous compounds.</li> <li>Sorting the DataFrame based on the number of outlier images provides a clear view of which compounds are most affected by outliers.</li> </ul>"},{"location":"user_guide/api/dataset/#get_cell_morphology_data","title":"<code>get_cell_morphology_data()</code>","text":"<p>Retrieves, processes, and aggregates cell morphology data from specified reference and flagged QC dataframes, utilizing user-defined parameters for detailed and nuanced analysis. This enhanced function now offers more flexibility in handling outlier data and custom aggregation methods, making it a central feature in the <code>pharmbio</code> package for cell morphology data management.</p>"},{"location":"user_guide/api/dataset/#syntax-source_15","title":"Syntax [source]","text":"<pre><code>def get_cell_morphology_data(\n    cell_morphology_ref_df: Union[pl.DataFrame, pd.DataFrame],\n    flagged_qc_df: Union[pl.DataFrame, pd.DataFrame] = None,\n    site_threshold: int = 6,\n    compound_threshold: float = 0.7,\n    aggregation_level: str = \"cell\",\n    aggregation_method: Optional[Dict[str, str]] = None,\n    path_to_save: str = \"data\",\n    use_gpu: bool = False,\n    save_plate_separately: bool = False\n) -&gt; pl.DataFrame:\n</code></pre>"},{"location":"user_guide/api/dataset/#parameters_15","title":"Parameters","text":"<ul> <li><code>cell_morphology_ref_df</code> (Union[pl.DataFrame, pd.DataFrame]): The reference DataFrame containing cell morphology data.</li> <li><code>flagged_qc_df</code> (Union[pl.DataFrame, pd.DataFrame], optional): Quality control DataFrame with flagged outlier images. Defaults to <code>None</code>.</li> <li><code>site_threshold</code> (int, optional): Threshold for the number of flagged sites in a well, above which the whole well is considered for removal. Range: 1-9. Defaults to 6.</li> <li><code>compound_threshold</code> (float, optional): Threshold for the percentage of data loss at which a compound is considered for deletion. Range: 0-1. Defaults to 0.7.</li> <li><code>aggregation_level</code> (str, optional): Level at which data aggregation is performed. Options: \"cell\", \"site\", \"well\", \"plate\", \"compound\". Defaults to \"cell\".</li> <li><code>aggregation_method</code> (Dict[str, str], optional): Methods of aggregation for each level, such as \"mean\", \"median\", etc. Defaults to <code>None</code>.</li> <li><code>path_to_save</code> (str, optional): Path for saving the aggregated data. Defaults to \"data\".</li> <li><code>use_gpu</code> (bool, optional): Flag for using GPU acceleration. Defaults to <code>False</code>.</li> <li><code>save_plate_separately</code> (bool, optional): Indicates whether to save aggregated data for each plate separately. Defaults to <code>False</code>.</li> </ul>"},{"location":"user_guide/api/dataset/#returns_14","title":"Returns","text":"<ul> <li><code>pl.DataFrame</code>: The aggregated cell morphology data as a DataFrame.</li> </ul>"},{"location":"user_guide/api/dataset/#raises_1","title":"Raises","text":"<ul> <li><code>EnvironmentError</code>: Raised when GPU acceleration is requested but not available.</li> <li><code>ValueError</code>: Raised for invalid <code>site_threshold</code> or <code>compound_threshold</code> values.</li> </ul>"},{"location":"user_guide/api/dataset/#examples_15","title":"Examples","text":"<p>To aggregate cell morphology data at the plate level, considering flagged QC data:</p> <pre><code>cell_morphology_ref_df = get_cell_morphology_ref(\"example_reference\")\nflagged_qc_df = # Assume pre-existing DataFrame with flagged QC data\naggregated_df = get_cell_morphology_data(\n    cell_morphology_ref_df,\n    flagged_qc_df,\n    site_threshold=6,\n    compound_threshold=0.7,\n    aggregation_level='plate'\n)\ndisplay(aggregated_df)\n</code></pre> <p>Info</p> <ul> <li>The function can optionally incorporates outlier handling based on flagged QC data, enhancing its robustness and reliability in processing complex cell morphology datasets.</li> <li>It offers flexible aggregation options at multiple levels, allowing for tailored analysis suited to specific experimental needs.</li> <li>GPU acceleration, if available, can significantly speed up data processing, especially for large datasets.</li> <li>The function takes a holistic approach to data aggregation, covering various steps such as data cleaning, joining, column reordering, and merging with additional plate information.</li> <li>The final output is a comprehensive and highly customizable DataFrame, enabling in-depth analysis of cell morphology data.</li> </ul>"},{"location":"user_guide/api/dataset/#pharmbiodatasetimage_quality","title":"<code>pharmbio.dataset.image_quality</code>","text":"<p>This module in the <code>pharmbio</code> package is dedicated to handling and querying image quality data.</p>"},{"location":"user_guide/api/dataset/#_get_image_quality_reference_df","title":"<code>_get_image_quality_reference_df()</code>","text":"<p>Retrieves an image quality reference dataframe along with an associated data dictionary from the database for a given experiment. This function is essential for obtaining image quality metadata and plate barcodes pertinent to a specific experiment, providing a foundation for image quality analysis.</p>"},{"location":"user_guide/api/dataset/#syntax-source_16","title":"Syntax [source]","text":"<pre><code>def _get_image_quality_reference_df(experiment_name: str) -&gt; (pl.DataFrame, dict):\n</code></pre>"},{"location":"user_guide/api/dataset/#parameters_16","title":"Parameters","text":"<ul> <li><code>experiment_name</code> (str): The name of the experiment for which image quality data is to be retrieved. This parameter is used to filter and fetch relevant data from the database.</li> </ul>"},{"location":"user_guide/api/dataset/#returns_15","title":"Returns","text":"<ul> <li><code>image_quality_reference_df</code> (pl.DataFrame): A dataframe containing image quality metadata specific to the experiment. This dataframe includes various metrics and information relevant to assessing the quality of images.</li> <li><code>data_dict</code> (dict): A dictionary mapping experiment names to lists of plate barcodes. This dictionary provides a quick reference to the plates associated with each experiment, facilitating further data processing or analysis.</li> </ul>"},{"location":"user_guide/api/dataset/#examples_16","title":"Examples","text":"<p>To retrieve image quality data for a specific experiment:</p> <pre><code>experiment_name = \"example_experiment\"\nimage_quality_ref_df, plate_barcodes_dict = _get_image_quality_reference_df(experiment_name)\n# image_quality_ref_df contains image quality metadata\n# plate_barcodes_dict maps experiment names to plate barcodes\n</code></pre> <p>Info</p> <ul> <li>The function constructs an SQL query using the provided <code>experiment_name</code>, the database schema, and the image quality metadata type (<code>IMAGE_QUALITY_METADATA_TYPE</code>).</li> <li>The resulting <code>image_quality_reference_df</code> contains detailed metadata for each image in the experiment, including various quality metrics and identifiers.</li> <li>The <code>data_dict</code> is created by grouping the DataFrame by the experiment name and aggregating plate barcodes. This dictionary is useful for quickly referencing which plates are associated with each experiment.</li> </ul>"},{"location":"user_guide/api/dataset/#_logging_information_image_quality_ref","title":"<code>_logging_information_image_quality_ref()</code>","text":"<p>Logs detailed information about a given image quality reference dataframe, data dictionary, and experiment name. This function is primarily used for logging and debugging purposes, providing insights into the data retrieved and any anomalies or patterns observed.</p>"},{"location":"user_guide/api/dataset/#syntax-source_17","title":"Syntax [source]","text":"<pre><code>def _logging_information_image_quality_ref(\n    image_quality_reference_df: pl.DataFrame,\n    image_quality_data_dict: Dict,\n    experiment_name: str,\n    unique_project_count: int\n):\n</code></pre>"},{"location":"user_guide/api/dataset/#parameters_17","title":"Parameters","text":"<ul> <li><code>image_quality_reference_df</code> (pl.DataFrame): A dataframe containing image quality metadata.</li> <li><code>image_quality_data_dict</code> (Dict): A dictionary mapping experiment names to lists of plate barcodes.</li> <li><code>experiment_name</code> (str): The name of the experiment being queried.</li> <li><code>unique_project_count</code> (int): The number of unique studies found for the given experiment.</li> </ul>"},{"location":"user_guide/api/dataset/#functionality","title":"Functionality","text":"<ul> <li>The function logs the number of studies found for the specified experiment name.</li> <li>It logs the details of the data dictionary, mapping experiments to plate barcodes.</li> <li>The function also identifies and logs any replicated analyses found in the dataframe, alerting to potential duplicates or redundancies in the data.</li> </ul>"},{"location":"user_guide/api/dataset/#examples_17","title":"Examples","text":"<p>The function is used internally for logging purposes. For example:</p> <pre><code>_logging_information_image_quality_ref(image_quality_ref_df, data_dict, \"Experiment_X\", unique_project_count)\n# This will log information, including the number of studies found and details about plate barcodes.\n</code></pre> <p>Info</p> <ul> <li>The function begins by constructing a message based on the number of unique studies found for the experiment, providing a quick overview of the query results.  It then iterates through the <code>image_quality_data_dict</code>, logging the experiment names and corresponding lists of plate barcodes. This provides clarity on the scope and range of the data retrieved.</li> <li>The function checks for replicated analyses within the dataframe. If duplicates are detected, it logs a warning with details about the replicated plates and their analysis IDs, which is crucial for data integrity checks.</li> <li>In the absence of replicated analyses, a log message confirms that no duplicates were found, ensuring data uniqueness and reliability.</li> <li>This logging function plays a critical role in data validation and error tracking, making it an essential tool for quality control and debugging in the data processing pipeline.</li> <li>By providing detailed logs, it aids in diagnosing issues with the data or the querying process, thereby facilitating efficient troubleshooting and ensuring the accuracy of the image quality analysis.</li> </ul>"},{"location":"user_guide/api/dataset/#get_image_quality_ref","title":"<code>get_image_quality_ref()</code>","text":"<p>Retrieves image quality reference data from the database based on the specified experiment name and optional filters. This function enables the selection and refinement of image quality data for specific experimental conditions, with capabilities to handle data replications and apply custom filters.</p>"},{"location":"user_guide/api/dataset/#syntax-source_18","title":"Syntax [source]","text":"<pre><code>def get_image_quality_ref(\n    name: str,\n    drop_replication: Union[str, List[int]] = \"Auto\",\n    keep_replication: Union[str, List[int]] = \"None\",\n    filter: dict = None\n) -&gt; pl.DataFrame:\n</code></pre>"},{"location":"user_guide/api/dataset/#parameters_18","title":"Parameters","text":"<ul> <li><code>name</code> (str): The name of the experiment for which to retrieve image quality reference data.</li> <li><code>drop_replication</code> (Union[str, List[int]], optional): Specifies which replications to drop. Can be set to \"Auto\" (to keep the latest experiment), \"None\", or a list of <code>analysis_id</code> values. Defaults to \"Auto\".</li> <li><code>keep_replication</code> (Union[str, List[int]], optional): Specifies which replications to keep. Can be \"None\" or a list of <code>analysis_id</code> values. Defaults to \"None\".</li> <li><code>filter</code> (dict, optional): A dictionary of filters to apply to the data. Defaults to None.</li> </ul>"},{"location":"user_guide/api/dataset/#returns_16","title":"Returns","text":"<ul> <li><code>polars.DataFrame</code>: A DataFrame containing the filtered image quality reference data.</li> </ul>"},{"location":"user_guide/api/dataset/#examples_18","title":"Examples","text":"<p>Retrieve specific image quality data with custom replication handling and filters:</p> <pre><code>name = \"example\"\ndrop_replication = [1, 2]\nkeep_replication = \"None\"\nfilter = {\"column1\": [\"value1\", \"value2\"], \"column2\": [\"value3\"]}\n\nresult = get_image_quality_ref(name, drop_replication, keep_replication, filter)\n# `result` is a DataFrame with the specified image quality data\n</code></pre> <p>Info</p> <ul> <li>The function initially retrieves image quality reference data using <code>_get_image_quality_reference_df</code>.</li> <li>It logs information about the data retrieved, including the number of unique studies found and details of plate barcodes.</li> <li>Based on <code>drop_replication</code> and <code>keep_replication</code> parameters, the function processes the DataFrame to retain or exclude specific replications.</li> <li>If filters are provided, it applies them to the DataFrame, allowing for refined data retrieval based on specific conditions.</li> <li>This flexibility in handling replications and applying filters makes the function highly adaptable for various scenarios to select the experiments.</li> <li>The function's ability to sort and uniquely identify data based on experimental needs ensures that users receive the most relevant and accurate image quality data for their specific queries.</li> </ul>"},{"location":"user_guide/api/dataset/#get_image_quality_data","title":"<code>get_image_quality_data()</code>","text":"<p>Retrieves and processes image quality data based on provided filtered information. This function serves as the main workflow for extracting, processing, and merging image quality data, allowing for various handling options based on user requirements.</p>"},{"location":"user_guide/api/dataset/#syntax-source_19","title":"Syntax [source]","text":"<pre><code>def get_image_quality_data(\n    filtered_image_quality_info: pl.DataFrame,\n    force_merging_columns: Union[bool, str] = False\n) -&gt; pl.DataFrame:\n</code></pre>"},{"location":"user_guide/api/dataset/#parameters_19","title":"Parameters","text":"<ul> <li><code>filtered_image_quality_info</code> (pl.DataFrame): The filtered image quality information, typically obtained from the <code>get_image_quality_ref</code> function.</li> <li><code>force_merging_columns</code> (Union[bool, str], optional): Specifies the method for merging columns. If set to <code>\"keep\"</code>, all columns are kept and missing values are filled with null. If <code>\"drop\"</code>, only matching columns are kept during horizontal merge. If <code>False</code>, the function returns <code>None</code>. Defaults to <code>False</code>.</li> </ul>"},{"location":"user_guide/api/dataset/#returns_17","title":"Returns","text":"<ul> <li><code>pl.DataFrame</code>: The concatenated and processed image quality data.</li> </ul>"},{"location":"user_guide/api/dataset/#examples_19","title":"Examples","text":"<p>Retrieve and process image quality data with specific merging preferences:</p> <pre><code>filtered_image_quality_ref = get_image_quality_ref(\"experiment_name\", drop_replication=\"Auto\")\nforce_merging_columns = \"keep\"\n\nresult = get_image_quality_data(filtered_image_quality_ref, force_merging_columns)\n# `result` is a DataFrame with processed image quality data\n</code></pre> <p>Info</p> <ul> <li>The function reads and processes files based on the information in <code>filtered_image_quality_info</code>, handling different file naming schemes and extensions.</li> <li>It casts numerical columns to appropriate data types (e.g., Float64 to Float32) for consistency and efficiency.</li> <li>The merging behavior is controlled by <code>force_merging_columns</code>, allowing for flexibility in how dataframes with different shape are combined.</li> <li>It logs successful imports and warnings for missing files, providing transparency in the data processing workflow.</li> <li>If <code>force_merging_columns</code> is set to \"keep\", the function merges the dataframes diagonally, ensuring that all columns are retained. In case of \"drop\", it keeps only the columns common across all dataframes.</li> </ul>"},{"location":"user_guide/api/logger/","title":"Logger","text":""},{"location":"user_guide/api/logger/#set_logger_levellevel","title":"<code>set_logger_level(level)</code>","text":"<p>Sets the logger's level to the specified logging level.</p>"},{"location":"user_guide/api/logger/#syntax-source","title":"Syntax [source]","text":"<pre><code>def set_logger_level(level: str):\n</code></pre>"},{"location":"user_guide/api/logger/#parameters","title":"Parameters","text":"<ul> <li><code>level</code> (str): The desired logging level. Accepted values are 'DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'.</li> </ul>"},{"location":"user_guide/api/logger/#raises","title":"Raises","text":"<ul> <li><code>ValueError</code>: Raised if an invalid log level is provided.</li> </ul>"},{"location":"user_guide/api/logger/#examples","title":"Examples","text":"<pre><code>set_logger_level('DEBUG')  # Sets the logging level to DEBUG\nset_logger_level('INFO')   # Sets the logging level to INFO\n</code></pre>"},{"location":"user_guide/api/logger/#log_debugmessage","title":"<code>log_debug(message)</code>","text":"<p>Logs a debug message.</p>"},{"location":"user_guide/api/logger/#syntax-source_1","title":"Syntax [source]","text":"<pre><code>def log_debug(message: str):\n</code></pre>"},{"location":"user_guide/api/logger/#parameters_1","title":"Parameters","text":"<ul> <li><code>message</code> (str): The message to be logged at the DEBUG level.</li> </ul>"},{"location":"user_guide/api/logger/#examples_1","title":"Examples","text":"<pre><code>log_debug('Debugging started')  # Logs a debug message\n</code></pre>"},{"location":"user_guide/api/logger/#log_infomessage","title":"<code>log_info(message)</code>","text":"<p>Logs an informational message.</p>"},{"location":"user_guide/api/logger/#syntax-source_2","title":"Syntax [source]","text":"<pre><code>def log_info(message: str):\n</code></pre>"},{"location":"user_guide/api/logger/#parameters_2","title":"Parameters","text":"<ul> <li><code>message</code> (str): The message to be logged at the INFO level.</li> </ul>"},{"location":"user_guide/api/logger/#examples_2","title":"Examples","text":"<pre><code>log_info('Process completed successfully')  # Logs an informational message\n</code></pre>"},{"location":"user_guide/api/logger/#log_warningmessage","title":"<code>log_warning(message)</code>","text":"<p>Logs a warning message.</p>"},{"location":"user_guide/api/logger/#syntax-source_3","title":"Syntax [source]","text":"<pre><code>def log_warning(message: str):\n</code></pre>"},{"location":"user_guide/api/logger/#parameters_3","title":"Parameters","text":"<ul> <li><code>message</code> (str): The message to be logged at the WARNING level.</li> </ul>"},{"location":"user_guide/api/logger/#examples_3","title":"Examples","text":"<pre><code>log_warning('Memory usage is high')  # Logs a warning message\n</code></pre>"},{"location":"user_guide/api/logger/#log_errormessage","title":"<code>log_error(message)</code>","text":"<p>Logs an error message.</p>"},{"location":"user_guide/api/logger/#syntax-source_4","title":"Syntax [source]","text":"<pre><code>def log_error(message: str):\n</code></pre>"},{"location":"user_guide/api/logger/#parameters_4","title":"Parameters","text":"<ul> <li><code>message</code> (str): The message to be logged at the ERROR level.</li> </ul>"},{"location":"user_guide/api/logger/#examples_4","title":"Examples","text":"<pre><code>log_error('Failed to connect to the database')  # Logs an error message\n</code></pre>"},{"location":"user_guide/api/logger/#log_criticalmessage","title":"<code>log_critical(message)</code>","text":"<p>Logs a critical message.</p>"},{"location":"user_guide/api/logger/#syntax-source_5","title":"Syntax [source]","text":"<pre><code>def log_critical(message: str):\n</code></pre>"},{"location":"user_guide/api/logger/#parameters_5","title":"Parameters","text":"<ul> <li><code>message</code> (str): The message to be logged at the CRITICAL level.</li> </ul>"},{"location":"user_guide/api/logger/#examples_5","title":"Examples","text":"<pre><code>log_critical('System failure: unable to recover')  # Logs a critical message\n</code></pre>"},{"location":"user_guide/api/utils/","title":"Utils","text":"<p>This module contains utility functions for file handling, data normalization, GPU detection, and GPU information retrieval in the <code>pharmbio</code> package.</p>"},{"location":"user_guide/api/utils/#get_file_extension","title":"<code>get_file_extension()</code>","text":"<p>Returns the file extension for the given file path (directory + filename).</p>"},{"location":"user_guide/api/utils/#syntax-source","title":"Syntax [source]","text":"<pre><code>def get_file_extension(file_path_name: str) -&gt; Optional[str]:\n</code></pre>"},{"location":"user_guide/api/utils/#parameters","title":"Parameters","text":"<ul> <li><code>file_path_name</code> (str): The path and name of the file without an extension.</li> </ul>"},{"location":"user_guide/api/utils/#returns","title":"Returns","text":"<ul> <li><code>Optional[str]</code>: The file extension if the file exists with any of the possible extensions [\".parquet\", \".csv\", \".tsv\"], otherwise <code>None</code>.</li> </ul>"},{"location":"user_guide/api/utils/#example","title":"Example","text":"<pre><code># Checking example.csv in the data directory\nfilename = \"data/example\"\nextension = get_file_extension(file_path_name)\nprint(extension)\n# Output: \".csv\"\n</code></pre>"},{"location":"user_guide/api/utils/#read_file","title":"<code>read_file()</code>","text":"<p>Reads a file with the specified filename and extension and returns a DataFrame.</p>"},{"location":"user_guide/api/utils/#syntax-source_1","title":"Syntax [source]","text":"<pre><code>def read_file(filename: str, extension: str) -&gt; Union[pl.DataFrame, None]:\n</code></pre>"},{"location":"user_guide/api/utils/#parameters_1","title":"Parameters","text":"<ul> <li><code>filename</code> (str): The name of the file to be read.</li> <li><code>extension</code> (str): The extension of the file.</li> </ul>"},{"location":"user_guide/api/utils/#returns_1","title":"Returns","text":"<ul> <li><code>Union[pl.DataFrame, None]</code>: The DataFrame read from the file, or <code>None</code> if the extension is not supported.</li> </ul>"},{"location":"user_guide/api/utils/#example_1","title":"Example","text":"<pre><code>filename = \"data\"\nextension = \".parquet\"\ndf = read_file(filename, extension)\nprint(df)\n</code></pre>"},{"location":"user_guide/api/utils/#normalize_df","title":"<code>normalize_df()</code>","text":"<p>Normalizes the values in the DataFrame using the specified normalization method.</p>"},{"location":"user_guide/api/utils/#syntax-source_2","title":"Syntax [source]","text":"<pre><code>def normalize_df(df: Union[pl.DataFrame, pd.DataFrame], method: Literal[\"zscore\", \"minmax\"] = \"zscore\") -&gt; pl.DataFrame:\n</code></pre>"},{"location":"user_guide/api/utils/#parameters_2","title":"Parameters","text":"<ul> <li><code>df</code> (Union[pl.DataFrame, pd.DataFrame]): The input DataFrame to be normalized.</li> <li><code>method</code> (Literal[\"zscore\", \"minmax\"], optional): The normalization method to be applied. Defaults to \"zscore\".</li> </ul>"},{"location":"user_guide/api/utils/#returns_2","title":"Returns","text":"<ul> <li><code>pl.DataFrame</code>: The normalized DataFrame.</li> </ul>"},{"location":"user_guide/api/utils/#example_2","title":"Example","text":"<pre><code>df = pd.DataFrame({\n    'A': [1, 2, 3, 4],\n    'B': [5, 6, 7, 8],\n    'C': [9, 10, 11, 12]\n})\nnormalized_df = normalize_df(df, method='minmax')\nprint(normalized_df)\n</code></pre>"},{"location":"user_guide/api/utils/#pretty_print_channel_dict","title":"<code>pretty_print_channel_dict()</code>","text":"<p>Prints the contents of a dictionary in a readable format for channel-related information.</p>"},{"location":"user_guide/api/utils/#syntax-source_3","title":"Syntax [source]","text":"<pre><code>def pretty_print_channel_dict(d: Dict[str, Any]):\n</code></pre>"},{"location":"user_guide/api/utils/#parameters_3","title":"Parameters","text":"<ul> <li><code>d</code> (Dict[str, Any]): A dictionary containing channel-related information.</li> </ul>"},{"location":"user_guide/api/utils/#has_gpu","title":"<code>has_gpu()</code>","text":"<p>Checks if the system has a GPU available using the \"nvidia-smi\" command.</p>"},{"location":"user_guide/api/utils/#syntax-source_4","title":"Syntax [source]","text":"<pre><code>def has_gpu() -&gt; bool:\n</code></pre>"},{"location":"user_guide/api/utils/#returns_3","title":"Returns","text":"<ul> <li><code>bool</code>: <code>True</code> if a GPU is available, <code>False</code> otherwise.</li> </ul>"},{"location":"user_guide/api/utils/#get_gpu_info","title":"<code>get_gpu_info()</code>","text":"<p>Retrieves GPU information including total memory and GPU count.</p>"},{"location":"user_guide/api/utils/#syntax-source_5","title":"Syntax [source]","text":"<pre><code>def get_gpu_info() -&gt; Tuple[Optional[int], Optional[int]]:\n</code></pre>"},{"location":"user_guide/api/utils/#returns_4","title":"Returns","text":"<ul> <li><code>Tuple[Optional[int], Optional[int]]</code>: A tuple containing the total memory in MB and the number of GPUs.</li> </ul>"},{"location":"user_guide/api/utils/#example_3","title":"Example","text":"<pre><code>total_memory, gpu_count = get_gpu_info()\nprint(f\"Total Memory: {total_memory} MB\")\nprint(f\"Number of GPUs: {gpu_count}\")\n</code></pre>"},{"location":"user_guide/api/visualization/","title":"Visualization","text":""},{"location":"user_guide/api/visualization/#plate_heatmap","title":"<code>plate_heatmap()</code>","text":"<p>Generates a heatmap visualization for plate data, providing insights into spatial distribution patterns across wells in a microplate format.</p>"},{"location":"user_guide/api/visualization/#syntax-source","title":"Syntax [source]","text":"<pre><code>def plate_heatmap(\n    df: Union[pl.DataFrame, pd.DataFrame],\n    plate_names: List[str] = None,\n    subplot_num_columns: int = 2,\n    plot_size: int = 400,\n    measurement: str = \"Count_nuclei\",\n    plate_well_columns: Dict[str, str] = None\n):\n</code></pre>"},{"location":"user_guide/api/visualization/#parameters","title":"Parameters","text":"<ul> <li><code>df</code> (Union[pl.DataFrame, pd.DataFrame]): The input data frame, either a polars or pandas DataFrame, containing the plate and well metadata along with measurement data.</li> <li><code>plate_names</code> (List[str], optional): A list of plate names to be visualized. If not provided, the function attempts to derive it from the data frame.</li> <li><code>subplot_num_columns</code> (int, optional): Number of columns for subplot layout. Default is 2.</li> <li><code>plot_size</code> (int, optional): Size of each subplot. Default is 400.</li> <li><code>measurement</code> (str, optional): The name of the measurement column in the data frame. Default is \"Count_nuclei\".</li> <li><code>plate_well_columns</code> (Dict[str, str], optional): A dictionary mapping the column names in <code>df</code> to the standard plate and well identifiers. Defaults to <code>{\"plates\": \"Metadata_Barcode\", \"wells\": \"Metadata_Well\"}</code>.</li> </ul>"},{"location":"user_guide/api/visualization/#returns","title":"Returns","text":"<ul> <li>The function does not return a value but displays the generated heatmap visualization directly.</li> </ul>"},{"location":"user_guide/api/visualization/#example","title":"Example","text":"<pre><code>import pandas as pd\nfrom pharmbio_package.pharmbio.visualization.plots import plate_heatmap\n\n# Sample DataFrame\ndata = {\n    \"Metadata_Barcode\": [\"Plate1\", \"Plate1\", \"Plate2\", \"Plate2\"],\n    \"Metadata_Well\": [\"A01\", \"A02\", \"B01\", \"B02\"],\n    \"Count_nuclei\": [10, 15, 5, 20]\n}\ndf = pd.DataFrame(data)\n\n# Generating the heatmap\nplate_heatmap(df)\n</code></pre>"},{"location":"user_guide/api/visualization/#_lineplot","title":"<code>_lineplot()</code>","text":"<p>Internal function used to generate line plots for different data frames.</p>"},{"location":"user_guide/api/visualization/#syntax-source_1","title":"Syntax [source]","text":"<pre><code>def _lineplot(\n    data_frames: pl.DataFrame,\n    colors: List[str],\n    title: str,\n    plate_names: List[str],\n    plot_size: int = 1400,\n    normalization: bool = True,\n    normalization_method: Literal[\"zscore\", \"minmax\"] = \"zscore\",\n    y_axis_range: Tuple = (-5, 5)\n):\n</code></pre>"},{"location":"user_guide/api/visualization/#parameters_1","title":"Parameters","text":"<p>This function is intended for internal use and may have dependencies on other parts of the <code>pharmbio_package</code>.</p>"},{"location":"user_guide/api/visualization/#quality_module_lineplot","title":"<code>quality_module_lineplot()</code>","text":"<p>Generates line plots for quality control modules, allowing for visualization of quality metrics across different plates.</p>"},{"location":"user_guide/api/visualization/#syntax-source_2","title":"Syntax [source]","text":"<pre><code>def quality_module_lineplot(\n    df: Union[pl.DataFrame, pd.DataFrame],\n    qc_module_to_plot: Set[str] = None,\n    title: str = \"Unnamed\",\n    plot_size: int = 1400,\n    normalization: bool = True,\n    normalization_method: Literal[\"zscore\", \"minmax\"] = \"zscore\",\n    y_axis_range: Tuple = (-5, 5),\n    colors: List[str] = COLORS\n):\n</code></pre>"},{"location":"user_guide/api/visualization/#parameters_2","title":"Parameters","text":"<ul> <li><code>df</code> (Union[pl.DataFrame, pd.DataFrame]): The input data frame, either a polars or pandas DataFrame, containing quality control data.</li> <li><code>qc_module_to_plot</code> (Set[str], optional): A set of quality control modules to plot. If not provided, default QC modules are used.</li> <li><code>title</code> (str, optional): Title of the plot. Default is \"Unnamed\".</li> <li><code>plot_size</code> (int, optional): The width of the plot in pixels. Default is 1400.</li> <li><code>normalization</code> (bool, optional): Whether to normalize data. Default is True.</li> <li><code>normalization_method</code> (Literal[\"zscore\", \"minmax\"], optional): Method used for normalization, either \"zscore\" or \"minmax\". Default is \"zscore\".</li> <li><code>y_axis_range</code> (Tuple, optional): The range of the y-axis. Default is (-5, 5).</li> <li><code>colors</code> (List[str], optional): List of colors for the line plots. Default is defined by <code>COLORS</code>.</li> </ul>"},{"location":"user_guide/api/visualization/#returns_1","title":"Returns","text":"<ul> <li>The function does not return a value but displays the generated line plots directly.</li> </ul>"},{"location":"user_guide/api/visualization/#example_1","title":"Example","text":"<pre><code>import pandas as pd\nfrom pharmbio_package.pharmbio.visualization.plots import quality_module_lineplot\n\n# Sample DataFrame\nqc_data = {\n    \"Metadata_Barcode\": [\"Plate1\", \"Plate1\", \"Plate2\", \"Plate2\"],\n    \"QC_Measure1\": [0.5, 0.7, 0.\n\n6, 0.4],\n    \"QC_Measure2\": [0.3, 0.2, 0.1, 0.4]\n}\ndf = pd.DataFrame(qc_data)\n\n# Generating quality module line plots\nquality_module_lineplot(df)\n</code></pre>"},{"location":"user_guide/api/visualization/#pad_with_zeros","title":"<code>pad_with_zeros()</code>","text":"<p>A utility function to pad a given vector with zeros, typically used for padding data arrays where cells on the edges are empty and not present in the data frame.</p>"},{"location":"user_guide/api/visualization/#syntax","title":"Syntax","text":"<pre><code>def pad_with_zeros(vector, pad_width, iaxis, kwargs):\n</code></pre>"},{"location":"user_guide/api/visualization/#parameters_3","title":"Parameters","text":"<ul> <li><code>vector</code>: The array or vector to be padded with zeros.</li> <li><code>pad_width</code>: A tuple specifying the number of zeros to pad at the beginning and end of the <code>vector</code>. The tuple format is <code>(pad_start, pad_end)</code>, where <code>pad_start</code> is the number of zeros to add at the start of the vector, and <code>pad_end</code> is the number of zeros to add at the end.</li> <li><code>iaxis</code>: The axis along which padding is to be applied. For a vector, this is typically the only axis (axis 0).</li> <li><code>kwargs</code>: Additional keyword arguments. This parameter is present for compatibility with padding functions but typically does not need to be used.</li> </ul>"},{"location":"user_guide/api/visualization/#returns_2","title":"Returns","text":"<ul> <li>The function modifies the input <code>vector</code> in place and does not return a separate value.</li> </ul>"},{"location":"user_guide/api/visualization/#example_2","title":"Example","text":"<pre><code>import numpy as np\nfrom pharmbio_package.pharmbio.visualization.plots import pad_with_zeros\n\n# Example vector\nvector = np.array([1, 2, 3, 4, 5])\n\n# Pad with two zeros at the start and three zeros at the end\npad_with_zeros(vector, (2, 3), 0, {})\n\nprint(vector)\n# Output will be an array padded with zeros: [0, 0, 1, 2, 3, 4, 5, 0, 0, 0]\n</code></pre>"},{"location":"blog/archive/2023/","title":"2023","text":""},{"location":"blog/category/data-analysis/","title":"Data analysis","text":""},{"location":"blog/category/outlier/","title":"Outlier","text":""}]}